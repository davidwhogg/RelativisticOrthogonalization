% Copyright 2024 the authors. All rights reserved.

% Style Notes
% -----------
% - Use $d\plus1$ for an in-text or wordy d+1, and $d+1$ for an in-equation or mathy $d+1$.
% - Don't put hyphens in timelike, spacelike, lightlike (null).
% - Typeset d-vectors and (d+1)-vectors using the macros, not by hand.
% - Use "~~" sparingly to make large separations in an equation but almost always use "~".

% To-do
% -----
% - Wrong title?
% - This paper is relevant, maybe? https://arxiv.org/abs/1103.1072
% - This paper is relevant, maybe? If only to criticize? https://arxiv.org/abs/2312.12969
% - Finish introduction including contributions and prior work.
% - Search for all HOGG, SOLE, \cite{} and fix them.
% - Stronger literature searches.
% - Do we say v_1,v_2,\ldots,v_n or do we say v_j, 1\leq j\leq n? Decide and flow it through (and add it to style notes).
% - Discuss the concept of a non-rotated frame. The decomposition between boost and rotation. So there is boost, rotation, time-reversal, and reflection: That's a four-part decomposition.
% - Discuss the fermi coordinates maybe?
% - We name-check Ricci calculus at the beginning but never return to it. should we? Hogg says no.
% - Put boxes around the figures.

\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{biblatex}
\addbibresource{sr.bib}
\graphicspath{{./notebooks/}}

% math definitions
\newcommand{\metric}{\mathsf{H}}
\usepackage{amsmath,amsfonts,mathrsfs}
\DeclareMathOperator{\dd}{d\!}
\newcommand\upvec[1]{\!\vec{\,\mathrm{#1}}}
\newcommand{\Evec}[1]{{\mathbf{#1}}} % d-vector
\newcommand{\Ehat}[1]{{\mathbf{\hat{#1}}}} % d-vector unit vector
\newcommand{\Lvec}[1]{\upvec{\mathsf{#1}}} % (d+1)-vector
\newcommand{\Lhat}[1]{\hat{\mathsf{#1}}} % (d+1)-vector unit vector
\newcommand{\inner}[2]{\langle{#1}\,,{#2}\rangle}
\newcommand{\bra}[1]{\langle\,{#1}\,|}
\newcommand{\ket}[1]{|\,{#1}\,\rangle}
\newcommand{\braket}[2]{\langle\,{#1}\,|\,{#2}\,\rangle}
\newcommand{\ketbra}[2]{|\,{#1}\,\rangle\,\langle\,{#2}\,|}
\newcommand{\plus}{\!+\!} % evil

% fixing latex page layout and typography
\usepackage[letterpaper]{geometry}
\setlength{\textwidth}{5.50in}
\setlength{\textheight}{9.40in}
\setlength{\oddsidemargin}{3.25in}
\addtolength{\oddsidemargin}{-0.5\textwidth}
\setlength{\topmargin}{-0.55in}
\renewcommand{\small}{\normalsize} % pure evil
\linespread{1.08}
\frenchspacing\raggedbottom\sloppy\sloppypar
\pagestyle{myheadings}
\markboth{}{\textsf{Hogg \& Villar / Relativistic orthogonalization and coordinate-free boost transforms}}
\newcommand{\documentname}{\textsl{Note}}
\newcommand{\secref}[1]{Section~\ref{#1}}
\newcommand{\figref}[1]{Figure~\ref{#1}}

% figure boxes and figure layout
\usepackage[framemethod=tikz]{mdframed}
\usetikzlibrary{shadows}
\definecolor{captiongray}{HTML}{555555}
\mdfsetup{%
  innertopmargin=2ex,
  innerbottommargin=1.8ex,
  linecolor=captiongray,
  linewidth=0.5pt,
  roundcorner=1pt,
  shadow=false,
  %shadowcolor=black!05,
  %hadowsize=4pt
}
\newlength{\figurewidth}
\setlength{\figurewidth}{0.315\textwidth}
\setlength{\floatsep}{1ex}
\setlength{\textfloatsep}{1ex}

\title{\bfseries Relativistic orthogonalization and coordinate-free Lorentz transformations}
\author{\textbf{David W. Hogg}\footnote{DWH is in the Center for Cosmology and Particle Physics, Department of Physics, New York University, and in the Max Planck Institute for Astronomy, and in the Center for Computational Astrophysics, Flatiron Institute. Send email to \texttt{<david.hogg@nyu.edu>}.}
        \and
        \textbf{Soledad Villar}\footnote{SV is in the Department of Applied Mathematics and Statistics, Johns Hopkins University, and in the Mathematical Institute of Data Science, Johns Hopkins University, and in the Center for Computational Mathematics, Flatiron Institute.}}
\date{incomplete draft as of 2024 August 03}

\begin{document}\thispagestyle{plain}
\maketitle

\begin{abstract}\noindent
    Special and general relativity in $d\plus1$ dimensions (our macroscopic Universe is $3\plus1$) can be thought of as metric theories with a metric that isn't positive definite, such that timelike, spacelike, and lightlike (null) vectors have positive, negative, and zero magnitudes.
    These spaces violate of a lot of the intuitions we have about subspaces, inner products, and orthogonality.
    The concept of orthogonalization (Gram--Schmidt, for example) carries over to Lorentz space (Minkowski space), but there are pathologies in which it is possible for the procedure to produce a lightlike vector and thus bork.
    We describe how to avoid this and successfully orthogonalize any $d+1$ linearly independent input vectors; every successful such orthogonalization produces one timelike and $d$ spacelike unit vectors, all orthogonal (in the Lorentz sense).
    We use this orthogonalization to construct coordinate-free representations of Lorentz transformations that fix or align particular vectors or subspaces.
    That is, we effectively present \emph{a new parameterization of the Lorentz transformations} for all Lorentz spaces $d\plus1$ (or even $d\plus s$).
\end{abstract}

\section{Introduction}\label{sec:intro}

Special relativity \cite{sr} is a purely kinematic theory, which can be formulated in terms of vector displacements between \emph{events}.
These vector displacements are 4-vectors in $(3\plus1)$-dimensional spacetime, which has three spatial dimensions and one time dimension.
The coordinate system can be varied not just by rotations and translations, but also by \emph{boosts}, in which the stationary observer (or equivalently the zero-point of 3-vector velocity) is redefined.
Most of the remarkable and counter-intuitive aspects of special relativity---time dilation, length contraction, twin paradox, and so on---flow from the fact that boost transformations preserve not the usual vector magnitudes and inner products, but instead magnitudes and inner products made with a \emph{non-positive-definite metric tensor}\footnote{For some, you can't call something a ``metric tensor'' if it isn't positive definite: How can you use a metric to define displacements if those displacements won't satisfy the triangle inequality? But that's where we are.}.
General relativity~\cite{gr} is a dynamical theory in which the non-positive-definite spacetime metric becomes (in general) a function of space and time, and the resulting curvature of spacetime is related to the energy densities and stresses in the matter and fields.
This \documentname{} is motivated partly by attempts to understand the geometric properties of spacetime with strange metrics---we will focus on special relativity---and to confront a few of the pathologies that arise.

For group theorists, $(3\plus1)$-dimensional special relativity is equivariant with respect to the group called the Lorentz group and denoted O($1,3$).
In $(d\plus1)$-dimensional spacetime the group would be O($1,d$).
The operators in the group O($1,d$) include rotations in the $d$-dimensional spatial subspace of spacetime, reflections in space and time, and boosts.
And then there are groups with \emph{multiple times}, such that it is $(d\plus s)$-dimensional spacetime and the group is O($s,d$).
All these groups are generalizations of the orthogonal group O($d$), which is the group of rotations and reflections in $d$-dimensional space.
In the context of group theory, the word ``equivariant'' means the following:
If you rotate, reflect, or boost the space, all of the predictions of the theory rotate, reflect, and boost appropriately to match.
What group theorists call ``equivariance'', physicists call ``covariance'' or ``symmetry''.

In some sense, the discovery of special relativity was the beginning of the discovery that physics can be stated in a coordinate-free form.
That is, one does not need to specify a coordinate system in order to explain the physical behavior of a system.
Sometimes a coordinate system is useful.
But it is usually not \emph{required}.
In the special relativity literature, the Lorentz transformations are almost always expressed in a particular coordinate system, aligned with the boost direction (see, eg \cite{foo})
Here we develop completely coordinate-free expressions for these operators in special relativity; our expressions depend on the change of velocity between the two frames, but not on the coordinate system in which this is expressed.

\paragraph{Our contributions:}
In this \documentname, we make a few new contributions to the discussion of special relativity:
\begin{itemize}
\item
HOGG: We orthogonalize, and make recommendations to avoid pathologies.
\item
HOGG: We construct the LT as a sum of outer products.
\item
HOGG: We develop a full analogy with Euclidean geometry.
\end{itemize}

\paragraph{Prior work:}
Some of the ideas discussed here have been looked at previously.
In particular, orthogonalization in special relativity is addressed in~\cite{joot}.
However, that previous work does not deal with the pathologies that can arise when orthogonalization is performed on arbitrary collections of vectors.
Coordinate-free Lorentz transformations are developed in~\cite{wagner}, but with a very different notation (in terms of 3-vectors, not 4-vectors) and a very different set of goals (HOGG CHECK THIS).

\section{Orthogonalization, projection, and rotation in O($d$)}\label{sec:od}

Before we consider special relativity, it is worth reviewing how an orthogonalization is performed, and how projection and rotation operators are constructed, in ordinary Euclidean space with an ordinary Euclidean metric.
In standard $d$-dimensional space, with the standard Euclidean metric (the identity), containing vectors governed by the standard orthogonal group O($d$), inner products (scalar products) of vectors are defined as follows:
Given two column vectors $\Evec{u},\Evec{v}\in\mathbb{R}^d$ (or, more specifically, $\mathbb{R}^{d\times1}$), the inner product $\inner{\Evec{u}}{\Evec{v}}\in\mathbb{R}$ is defined as
\begin{align}
    \inner{\Evec{u}}{\Evec{v}} &\equiv \Evec{u}^\top \Evec{v} = \Evec{v}^\top \Evec{u} ~.
\end{align}
Two vectors $\Evec{u},\Evec{v}$ are considered orthogonal if their inner product vanishes, or $\inner{\Evec{u}}{\Evec{v}}=0$.
In Euclidean space, we will call these vectors \emph{$d$-vectors} and typeset them bold.

Imagine that we are given a collection of $n\leq d$ linearly independent $d$-vectors $\Evec{v}_1,\Evec{v}_2,\ldots,\Evec{v}_n$,
and we want to construct orthonormal basis vectors $\Ehat{u}_1,\Ehat{u}_2,\ldots,\Ehat{u}_n$ that span the linear subspace spanned by the vectors $\Evec{v}_j$.
We can perform this orthonormalization by the Gram--Schmidt process \cite{gramschmidt}:
We sequentially construct orthogonal vectors $\Evec{u}_1,\Evec{u}_2,\ldots,\Evec{u}_n$ and normalize them into orthogonal unit vectors $\Ehat{u}_1,\Ehat{u}_2,\ldots,\Ehat{u}_n$ by the following algorithm:
\begin{align}
    \Evec{u}_1 &\leftarrow \Evec{v}_1 \label{eq:ogs1}
    \\
    \mbox{then for each $j$ ($2\leq j\leq n$) in order:} ~~ \Evec{u}_j &\leftarrow \Evec{v}_j - \sum_{k=1}^{j-1} \frac{\inner{\Evec{v}_j}{\Evec{u}_k}}{\inner{\Evec{u}_k}{\Evec{u}_k}}\,\Evec{u}_k \label{eq:ogs2}
    \\
    \mbox{then for each $j$ ($1\leq j\leq n$):} ~~ \Ehat{u}_j &\leftarrow \frac{1}{\sqrt{\inner{\Evec{u}_j}{\Evec{u}_j}}}\,\Evec{u}_j ~. \label{eq:ogs3}
\end{align}
Note that the procedure in \eqref{eq:ogs2} is order-dependent: If you put the $d$-vectors $\Evec{v}_1,\Evec{v}_2,\ldots,\Evec{v}_n$ into a different order, the orthogonalization will return different specific basis unit vectors $\Ehat{u}_1,\Ehat{u}_2,\ldots,\Ehat{u}_n$.
However, all the different possible returned bases (under permutations of the $\Evec{v}_j$) will span the same $n$-dimentional linear subspace of the $d$-dimentional space.

The reader might be concerned that the orthogonalization involves division by forms like $\sqrt{\inner{\Evec{u}}{\Evec{u}}}$.
Provided that the input vectors are nonzero and linearly independent, this divisor will never vanish.
That situation will change when we consider the relativistic case in \secref{sec:orth}.

If you have $n\leq d$ linearly independent $d$-vectors $\Evec{v}_j$ that span an $n$-dimensional subspace $\mathscr{S}$ of the $d$-dimensional space, you can use this orthonormalization procedure to build a subspace projection operator $\Pi_\mathscr{S}$
\begin{align}\label{eq:oproj}
    \Pi_\mathscr{S} &= \sum_{j=1}^n \Ehat{u}_j\,\Ehat{u}_j^\top ~,
\end{align}
where the $\Ehat{u}_j$ are the orthogonal unit vectors\footnote{Note that because---for us---all vectors $\Evec{u},\Evec{v}$ are column vectors, $\Evec{u}\,\Evec{v}^\top\in\mathbb{R}^{d\times d}$ while $\Evec{u}^\top \Evec{v}\in\mathbb{R}$.} delivered by the orthonormalization procedure applied to the $\Evec{v}_j$.
This projection operator has the property that, for any vector $\Evec{w}\in\mathbb{R}^d$, the vector $\Pi_\mathscr{S}\,\Evec{w}$ will lie in the subspace spanned by the $\Evec{v}_j$.
One consequence of this line of reasoning is that if you have $n=d$ linearly independent vectors $\Evec{v}_j$, they will span the whole space, and the projection operator $\Pi_\mathscr{S}$ will become the $d$-dimensional identity matrix $I_d$.
That is, if you have an orthonormal basis of $d$ unit vectors $\Ehat{u}_j$,
\begin{align}\label{eq:oI}
    I_d &= \sum_{j=1}^d \Ehat{u}_j\,\Ehat{u}_j^\top = \sum_{j=1}^d \frac{\Evec{u}_j\,\Evec{u}_j^\top}{\inner{\Evec{u}_j}{\Evec{u}_j}} ~,
\end{align}
where we have written it in terms of both the normalized and un-normalized vectors, anticipating results to come.
Physicists might call these forms for $\Pi_\mathscr{S}$ and $I_d$ \emph{coordinate-free}:
They are coordinate-free in the sense that they are stated just in terms of the input vectors, not in terms of matrix components.
Or, equivalently, we didn't have to specify my coordinate system when we constructed them; we only had to specify the vectors that span the subspace.

These aren't the only kinds of operators that can be written in this coordinate-free form.
It is also possible to write any rotation-reflection operator $R$ in a coordinate-free form.
First a definition: A matrix $R\in\mathbb{R}^{d\times d}$ is a rotation-reflection operator in the orthogonal group O($d$) if the operator preserves all inner products (scalar products).
That is,
\begin{equation}
    R \in \mbox{O($d$)} ~ \mbox{if and only if} ~ \inner{\Evec{u}}{\Evec{v}}=\inner{R\,\Evec{u}}{R\,\Evec{v}} ~ \mbox{for all $\Evec{u},\Evec{v}$ in $\mathbb{R}^d$} ~.\label{eq:orth1}
\end{equation}
This, in turn, will be true if and only if $R$ is a square root of the identity:
\begin{equation}
    R \in \mbox{O($d$)} ~ \mbox{if and only if} ~ R^\top R=I_d ~.\label{eq:orth2}
\end{equation}
We call $R$ a rotation-reflection operator because the group encompasses all rotations, all reflections, and all combinations of rotations and reflections.

For example, the simplest (interesting) orthogonal space is $O(2)$. In this case the operators form a one-dimensional family; they are all of the form
\begin{align}
    R &= \begin{bmatrix}\cos{\theta} & -\sin{\theta} \\ \sin{\theta} & \cos{\theta}\end{bmatrix} ~\mbox{or}~
    \begin{bmatrix}-\cos{\theta} & \sin{\theta} \\ \sin{\theta} & \cos{\theta}\end{bmatrix} \label{eq:o2}
    \\
    -\pi &< \theta < \pi ~, \nonumber
\end{align}
where $\theta$ is a rotation angle.
The two choices in \eqref{eq:o2} correspond to, in one case, pure rotation and, in the other, rotation plus reflection.
When $d>2$ the coordinate representations of the $R$ become large matrices full of trig functions.
They get very complicated, while the coordinate-free representations we are about to deliver stay simple.

Now how do we construct general coordinate-free forms for the operators $R$?
Usually they are given in terms of sines and cosines of rotation angles, plus sign flips, as they are in \eqref{eq:o2}.
However, there are coordinate-free forms.
For example: Imagine that we have two complete orthonormal bases in $\mathbb{R}^d$, $\Ehat{u}_1,\Ehat{u}_2,\ldots,\Ehat{u}_d$ and $\Ehat{u}'_1,\Ehat{u}'_2,\ldots,\Ehat{u}'_d$.
We can now imagine a rotation-reflection operator $R$ that rotates and reflects any $d$-vector $\Evec{w}$ in the same way that these two bases are rotated and reflected with respect to one another.
This particular operator $R$ can be constructed by the following coordinate-free outer-product construction:
\begin{align}
    R &= \sum_{j=1}^d \Ehat{u}'_j\,\Ehat{u}_j^\top ~.\label{eq:rotationoperator}
\end{align}
That is, rotations and reflections can be specified directly using orthonormal bases, with no explicit reference to any angles or coordinates.
In this sense, this form could be thought of as a ``vector-guided'' rotation matrix:
It is constructed directly from the vectors, and independent of how those vectors are represented.
It is therefore coordinate-free.
In case it is unfamiliar, this form \eqref{eq:rotationoperator} for transformation operators is advocated for and used in, eg, \cite{kusse}.

Here's an irrelevant aside:
If your background is quantum mechanics, then you probably use bra--ket (braket and ketbra) notation.
For you an inner product is written as a braket $\braket{\Evec{u}}{\Evec{v}}$, and an outer product is written as a ketbra $\ketbra{\Evec{u}}{\Evec{v}}$.
In this notation, the rotation-reflection operator $R$ can be written 
\begin{align}
    R &= \sum_{j=1}^d \ketbra{\Ehat{u}'_j}{\Ehat{u}_j} ~,
\end{align}
which looks just like a change-of-basis operator in quantum mechanics (see, for example,~\cite{quantumtextbook}).

\begin{figure}[t]
\begin{mdframed}
\includegraphics[width=\figurewidth]{E_v.png}%
\includegraphics[width=\figurewidth]{E_vp.png}%
\includegraphics[width=\figurewidth]{E_Q.png}
\caption{A demonstration of orthogonalization and rotation in Euclidean 2-dimensional space O(2).
    \textsl{Left:} Two 2-vectors $\Evec{v}_1, \Evec{v}_2$ and the corresponding orthonormal 2-vectors $\Ehat{u}_1, \Ehat{u}_2$ obtained by the orthogonalization procedure.
\textsl{Middle:} A different two vectors $\Evec{v}'_1, \Evec{v}'_2$ and the corresponding orthonormal vectors $\Ehat{u}'_1, \Ehat{u}'_2$.
\textsl{Right:} The action of the rotation operator $R$ generated from the orthonomal pairs $\Ehat{u}_1, \Ehat{u}_2$ and $\Ehat{u}'_1, \Ehat{u}'_2$.
The black points rotate to the red points under the action of the operator $R$.
The grey points in between are presented to guide the eye.\label{fig:Euclid}}
\end{mdframed}
\end{figure}
The result of orthogonalization of two pairs of 2-vectors in O(2) ($d=2$) is shown in \figref{fig:Euclid}.
Also shown in \figref{fig:Euclid} is the action of the rotation operator $R$ derived from the basis vectors generated by those two orthogonalizations.

\section{Relativistic notation and transformations}\label{sec:notation}

There is a history of notation in special and general relativity.
Here we deliver a translation from traditional Einstein summation notation, and traditional language about boost, to a more linear-algebra-oriented notation.
After this Section, we will be using exclusively the linear-algebra notation, which is simpler (for us).

In Lorentz or Minkowski space, we think of there being a metric $\metric$ (often called $g_{\mu\nu}$), which is a $(d\plus1)\times(d\plus1)$ matrix that is \emph{not} positive definite.
The metric $\metric$ is diagonal with $+1$ in the first position and $-1$ repeated on all the remaining $d$ diagonal elements.
In $3\plus1$ this is
\begin{align}\label{eq:sig}
    \metric &= \begin{bmatrix}1 & 0 & 0 & 0\\
                              0 & -1 & 0 & 0\\
                              0 & 0 & -1 & 0\\
                              0 & 0 & 0 & -1\end{bmatrix} ~.
\end{align}
There is another possible signature---with $-1$ in the first position and $+1$ thereafter.
In this \documentname{} we choose the signature illustrated in \eqref{eq:sig}; nothing significant in our discussion changes if you choose the opposite signature.
Indeed, this is one of the main reasons to pursue the coordinate-free representations pursued here:
The coordinate-free representations don't care about the signature of your metric, or any other aspects of your coordinate system.\footnote{It is precisely because the choice of signature doesn't matter that physicists will constantly argue about it. We don't know many physicists who don't have a strong opinion about the signature. We ourselves have no strong opinion, and our expressions are agnostic to the signature.}
The signature of the metric will only come up in our definitions of ``timelike'' \eqref{eq:timelike}, ``lightlike'' \eqref{eq:lightlike}, and ``spacelike'' \eqref{eq:spacelike} below.

The metric we have described is the metric for $d\plus 1$.
In $d\plus s$ the diagonal of the metric has $s$ values set to $+1$ and $d$ values set to $-1$ (or the opposite for the opposite signature).

We are going to consider vectors $\Lvec{u}, \Lvec{v}\in\mathbb{R}^{(d+1)}$ in Lorentz space or Minkowski space or spacetime.
We will call these vectors \emph{$(d\plus1)$-vectors}, and typeset them sanserif with hats (arrows or carets, depending).

Old-school relativists tend to write the relativistic inner product $\inner{\Lvec{u}}{\Lvec{v}}\in\mathbb{R}$ (the scalar product or Minkowski inner product) between two $(d\plus1)$-vectors $\Lvec{u}$ and $\Lvec{v}$ as
\begin{align}
    \inner{\Lvec{u}}{\Lvec{v}} &= \Lvec{u}^\mu\,\Lvec{v}_\mu = \Lvec{v}^\mu\,\Lvec{u}_\mu ~,
\end{align}
where $\mu$ is a component index\footnote{In this \documentname{}, greek indexes like $\mu$, $\nu$ will be indexes over vector components (going from 1 to 4 in $3\plus1$, for example), and roman indexes like $i$, $j$ will be indexes over vectors or other things.} going from 1 to $d+1$, and the repeated index is (implicitly) summed.
The $\Lvec{u}^\mu$ is a contravariant vector component and the $\Lvec{v}_\mu$ is a covariant vector component.
Contravariant and covariant components are related as follows:
\begin{align}
    \Lvec{u}^\mu &= \metric^{\mu\nu}\,\Lvec{u}_\nu \equiv \sum_{\nu=1}^{d+1} \metric^{\mu\nu}\,\Lvec{u}_\nu
    \\
    \inner{\Lvec{u}}{\Lvec{v}} &= \Lvec{u}^\mu\,\Lvec{v}_\mu = \metric^{\mu\nu}\,\Lvec{u}_\mu\,\Lvec{v}_\nu \equiv \sum_{\mu=1}^{d+1}\sum_{\nu=1}^{d+1} \metric^{\mu\nu}\,\Lvec{u}_\mu\,\Lvec{v}_\nu
\end{align}
where the $\metric^{\mu\nu}$ are the components of the metric $\metric$.
The implicit summations on the left of the ``$\equiv$'' signs are guided by the rules of what's called Einstein summation notation (\cite{summation}; it is a subset of the Ricci calculus~\cite{ricci}): Indexes can appear exactly once or exactly twice (and no more) and when they appear twice, one must be up and one must be down, and they are summed from 1 to $d+1$.
In quantum-mechanics (braket) notation, a covariant vector is like a bra $\bra{\Lvec{v}}$, and a contravariant vector is like a ket $\ket{\Lvec{v}}$,
an inner product is a braket $\braket{\Lvec{u}}{\Lvec{v}}$, and an outer product (to appear below) is a ketbra $\ketbra{\Lvec{u}}{\Lvec{v}}$.

In linear algebra notation, if we think of $\Lvec{u}$ and $\Lvec{v}$ as being column vectors in $\mathbb{R}^{d+1}$ (or, to be extremely specific, $\mathbb{R}^{(d+1)\times 1}$), then we can write this same inner product as
\begin{align}\label{eq:inner}
    \inner{\Lvec{u}}{\Lvec{v}} &\equiv \Lvec{u}^\top\metric\,\Lvec{v} = \Lvec{v}^\top\metric\,\Lvec{u} ~.
\end{align}
We are going to use this notation going forward, not the Einstein summation notation.

What, physically, are the $(d\plus1)$-vectors of special relativity?
Events in spacetime are represented by one time coordinate and three spatial coordinates (a position); they are things that happened at some place and time.
The displacement $\Lvec{s}$ between two events is a $(d\plus1)$-vector.
In $d\plus1$ there are generalizations of many standard $d$-vectors to which you are accustomed.
For example,
the $(d\plus1)$-vector velocity $\Lvec{u}$ is a timelike vector with $\inner{\Lvec{u}}{\Lvec{u}}=1$ (a unit vector), where the spatial part of $\Lvec{u}$ (the last $d$ components) is proportional to what is traditionally the $d$-vector velocity.
In $d=3$ spatial dimensions the $(3\plus1)$-vector velocity $\Lvec{u}$ is given by
\begin{align}
    \Lvec{u}^\top &= \begin{bmatrix} \gamma & \gamma\,\beta_x & \gamma\,\beta_y & \gamma\,\beta_z \end{bmatrix} \\
    \gamma &= (1 - \beta_x^2 - \beta_y^2 - \beta_z^2)^{-1/2} \nonumber\\
    \begin{bmatrix} \beta_x & \beta_y & \beta_z\end{bmatrix} &= \begin{bmatrix}\displaystyle\frac{1}{c}\,\frac{\dd x}{\dd t} & \displaystyle\frac{1}{c}\,\frac{\dd y}{\dd t} & \displaystyle\frac{1}{c}\,\frac{\dd z}{\dd t} \end{bmatrix} = \frac{1}{c}\,\Evec{v}^\top ~,\nonumber
\end{align}
where the transpose on $\Lvec{u}$ is a reminder that $(d\plus1)$-vectors are really column vectors,
$c$ is the speed of light in a vacuum (or the speed of lightlike or null trajectories),
and the $\beta_k$ are the components of a dimensionless 3-vector velocity $\Evec{v}/c$.
Explicit calculation demonstrates that $\inner{\Lvec{u}}{\Lvec{u}}=1$ for all settings of $\Evec{v}/c$.
Another $(d\plus1)$-vector example is the $(d\plus1)$-vector momentum $\Lvec{p}$ of a particle.
This is a timelike vector with $\inner{\Lvec{p}}{\Lvec{p}}=m^2\,c^4$, where $m$ is the rest mass of the particle.
The $(d\plus1)$-vector momentum has the energy $E$ of the particle as its first component (the time component), and $c$ times the standard $d$-vector momentum $\Evec{p}$ in its remaining $d$ components.\footnote{%
If you write out the inner product $\inner{\Lvec{p}}{\Lvec{p}}$ for the $(d\plus1)$-vector momentum $\Lvec{p}$ and rearrange, you get $$E^2 + |\Evec{p}|^2\,c^2 = m^2\,c^4~,$$ where $\Evec{p}$ is the $d$-vector (spatial) momentum. In the rest frame, this becomes $E=m\,c^2$. This is the equation that made Einstein famous.}

When you change reference frames, a Lorentz transformation is applied.
Under the Lorentz transformation, the components of all of the $(d\plus1)$-vectors will change, but all the inner products among them (and with themselves) will remain the same.

In standard special-relativity lore, Lorentz transformations are taught as \emph{boost transformations} in which the assignment of the stationary observer is changed and the time and space axes change accordingly.
For our purposes, the Lorentz transformations also include spatial rotations, spatial reflections, and even time reflections (gasp!):
That is, for our purposes, an operator $Q$ is a valid Lorentz transformation if it is a member of the Lorentz group O($1,d$).
To be more specific, an operator $Q$ (which can be thought of as a $(d+1)\times(d+1)$ matrix) is a Lorentz transformation---is in O($1,d$)---if it preserves all inner products (scalar products). 
That is,
\begin{equation}
    Q \in \mbox{O($1,d$)} ~ \mbox{if and only if} ~ \inner{\Lvec{u}}{\Lvec{v}}=\inner{Q\,\Lvec{u}}{Q\,\Lvec{v}} ~ \mbox{for all $\Lvec{u},\Lvec{v}$ in $\mathbb{R}^{d+1}$} ~.\label{eq:lore1}
\end{equation}
This, in turn, will be true if and only if $Q$ leaves the metric unchanged:
\begin{equation}
    Q \in \mbox{O($1,d$)} ~ \mbox{if and only if} ~ Q^\top\metric\,Q=\metric ~.\label{eq:lore2}
\end{equation}
This is our (surprising, perhaps) definition of the Lorentz transformation $Q$.
Note how similar the Lorentz-group statements \eqref{eq:lore1} and \eqref{eq:lore2} are to the orthogonal-group statements \eqref{eq:orth1} and \eqref{eq:orth2}.

For example, the simplest Lorentz space is O($1,1$) or $1\plus1$ ($d=1$).
In this case, the Lorentz transformations form a one-dimensional family; they are all of the form
\begin{align}
    Q &= \begin{bmatrix}\gamma & \beta\,\gamma \\ \beta\,\gamma & \gamma\end{bmatrix} ~\mbox{or}~
    \begin{bmatrix}-\gamma & -\beta\,\gamma \\ \beta\,\gamma & \gamma\end{bmatrix} ~\mbox{or}~
    \begin{bmatrix}\gamma & \beta\,\gamma \\ -\beta\,\gamma & -\gamma\end{bmatrix}  ~\mbox{or}~
    \begin{bmatrix}-\gamma & -\beta\,\gamma \\ -\beta\,\gamma & -\gamma\end{bmatrix} \label{eq:o11}
    \\
    \gamma &\equiv \frac{1}{\sqrt{1 - \beta^2}} ~ \mbox{and} ~ -1 < \beta < 1 ~.\nonumber
\end{align}
In this simple case, $\beta$ is the dimensionless velocity of the boost, and $\gamma$ is the Lorentz factor.
The four choices in \eqref{eq:o11} correspond to even parity, reversing time (after the boost), reversing space (after the boost), and reversing both.\footnote{%
Many physicists would not permit reversals of time or space among the Lorentz transformations.
These reversals appear inevitably when we define the set of Lorentz transformations to be all the operators $Q$ such that $\metric=Q^\top\metric\,Q$, as we do.
So we depart here slightly from standard practice by being maximally inclusive.}
But in what follows we are going to develop \emph{coordinate-free forms} for the Lorentz transformations, in analogy to the coordinate-free forms for the rotation-reflection operators given in \secref{sec:od}.

Finally we remark that---because the metric is non-positive-definite---a nonzero $(d\plus1)$-vector $\Lvec{v}$ can come in three forms, \emph{timelike}, \emph{spacelike}, or \emph{lightlike} (sometimes \emph{null}):
\begin{align}
    \Lvec{v} ~ \mbox{is timelike}  &~ \mbox{if} ~ \inner{\Lvec{v}}{\Lvec{v}} > 0 \label{eq:timelike}\\
    \Lvec{v} ~ \mbox{is lightlike} &~ \mbox{if} ~ \inner{\Lvec{v}}{\Lvec{v}} = 0 \label{eq:lightlike}\\
    \Lvec{v} ~ \mbox{is spacelike} &~ \mbox{if} ~ \inner{\Lvec{v}}{\Lvec{v}} < 0 ~.\label{eq:spacelike}
\end{align}
Technically, these definitions depend on the signature you chose for your metric; you would use the opposite language if you chose the opposite signature.
This is the only point in this \documentname{} that depends on the signature; everything else is agnostic to signature.
Because Lorentz transformations $Q\in$~O($1,d$) preserve inner products, you can't Lorentz transform a vector from any one of these three categories (timelike, lightlike, or spacelike) to any other of these categories; the category is a Lorentz invariant property of the $(d\plus1)$-vector.

\section{Relativistic orthogonalization}\label{sec:orth}

In Lorentz space we will still say that two $(d\plus1)$-vectors are ``orthogonal'' if their inner product is zero.
\begin{align}
    \Lvec{u},\Lvec{v} ~ \mbox{are orthogonal if and only if} ~ \inner{\Lvec{u}}{\Lvec{v}}=0 ~,
\end{align}
where the inner product is defined as in \eqref{eq:inner}.
This is great, but it leads to a strange consequence:
Any lightlike vector $\Lvec{v}$ is \emph{orthogonal to itself}.
This is just one aspect of the oddness of orthogonality under the Lorentz metric:
It is also the case that orthogonal vectors aren't generally at 90 degrees with respect to each other; in fact angles aren't obviously defined for general $(d\plus1)$-vectors in spacetime.

We will still have linear dependence and independence exactly as in Euclidean space:
$n$ $(d\plus1)$-vectors $\Lvec{v}_j$ are linearly independent if there is no non-trivial set of amplitudes $a_j\in\mathbb{R}$ such that $\sum_{j=1}^n a_j\,\Lvec{v}_j = 0$.

How does orthogonalization and orthonormalization work in relativity?
Start with $n\leq d+1$ linearly independent $(d\plus1)$-vectors $\Lvec{v}_1,\Lvec{v}_2,\ldots,\Lvec{v}_n$.
If these vectors are randomly generated, then with high probability the straightforward generalization of Gram--Schmidt will work:
\begin{align}
    \Lvec{u}_1 &\leftarrow \Lvec{v}_1 \label{eq:rgs1}
    \\
    \mbox{then for each $j$ ($2\leq j\leq n$) in order:} ~~ \Lvec{u}_j &\leftarrow \Lvec{v}_j - \sum_{k=1}^{j-1} \frac{\inner{\Lvec{v}_j}{\Lvec{u}_k}}{\inner{\Lvec{u}_k}{\Lvec{u}_k}}\,\Lvec{u}_k \label{eq:rgs2}
    \\
    \mbox{then for each $j$ ($1\leq j\leq n$):} ~~ \Lhat{u}_j &\leftarrow \frac{1}{\sqrt{|\inner{\Lvec{u}_j}{\Lvec{u}_j}|}}\,\Lvec{u}_j ~, \label{eq:rgs3}
\end{align}
where we had to insert an absolute value inside the square-root operation because negative inner products will appear.
We're done. \emph{Ta-da!}
But we aren't really done, because the iteration step \eqref{eq:rgs2} involves dividing by an inner product, and inner products can vanish if the procedure accidentally produces a lightlike vector $\Lvec{u}_j$ for some $j$.

In principle (and in practice if your context is adversarial), the orthogonalization procedure in \eqref{eq:rgs2} can produce a lightlike vector.
If you start with $n$ linearly independent $(d\plus1)$-vectors $\Lvec{v}_j$, ($1\leq j\leq n$), begin the orthogonalization procedure, and then at some $j$ produce a lightlike $\Lvec{u}_j$, here are the strategies:
\begin{enumerate}
\item If all your input vectors $\Lvec{v}_j$ are lightlike, then by construction, $\Lvec{u}_1$ will be lightlike.
    Replace the first two input vectors $\Lvec{v}_1,\Lvec{v}_2$ with two (possibly randomly constructed) independent linear combinations of the $\Lvec{v}_1$ and $\Lvec{v}_2$.
    Re-start the orthogonalization.
    With high probability the orthogonalization will succeed.
    \item If not every one of your input vectors is lightlike, but the first one is, then by construction ${u}_1$ will be lightlike.
    Reorder the vectors such that the first vector is not lightlike and re-start the orthogonalization.
    With high probability the orthogonalization will succeed.
    \item If none of your input vectors is lightlike, but a lightlike $\Lvec{u}_j$ is appearing, reorder the input vectors and re-start the orthogonalization.
    \item If all of the above fails, replace the $n$ input vectors $\Lvec{v}_j$ with a randomly generated set of $n$ indepdent linear combinations of the original $n$ input vectors.
    With high probability orthogonalization will succeed on this new set of inputs (and, by construction, it will span the same subspace as the original input vectors).
\end{enumerate}
These rules aren't extremely satisfying, because (unless you are extremely careful) they involve changing things like the orientation of the coordinate system.
We conjecture that there are better possible rules.

HOGG SAY: I think if we start with one timelike first and $n-1$ linearly independent spacelike afterwards, nothing ever borks.
So just do that! MAYBE?

One comment to make is that orthogonalization is not necessarily numerically stable.
That is, a set of vectors can be formally linearly independent, but only barely, or not at all at finite precision.
It is out of scope for us here, but there are methods to improve the stability of orthogonalizations (SOLE WHAT TO CITE?); these will be generalizable to the Lorentz space.

Another comment to make is that if you start with $n=d+1$ linearly independent $(d\plus1)$-vectors, the outcome of the orthogonalization will be exactly one timelike vector and exactly $d$ spacelike vectors.
Importantly for what follows, \emph{the algorithm-generated set of normalized unit vectors $\Lhat{u}_1,\Lhat{u}_2,\ldots,\Lhat{u}_{d+1}$ will form a coordinate basis in spacetime}, with one timelike (time) axis unit vector and $d$ orthogonal spacelike (spatial) axis unit vectors.

Now just like in O($d$) you can use the orthogonalization to make a subspace projection operator.
If you have $n\leq d+1$ linearly independent $(d\plus1)$-vectors that span a subspace $\mathscr{T}$, then you can orthogonalize them and construct the subspace projection operator $\Pi_\mathscr{T}$
\begin{align}\label{eq:rproj}
    \Pi_\mathscr{T} &= \sum_{j=1}^n \frac{\Lhat{u}_j\,\Lhat{u}_j^\top\metric}{\inner{\Lhat{u}_j}{\Lhat{u}_j}} = \sum_{j=1}^n \frac{\Lvec{u}_j\,\Lvec{u}_j^\top\metric}{\inner{\Lvec{u}_j}{\Lvec{u}_j}} ~,
\end{align}
where the $\Lhat{u}_j$ are the orthogonal unit vectors, and the $u_j$ are the un-normalized orthogonal vectors; this differs from the result in \eqref{eq:oproj} in that we have to divide by an inner product $\inner{\Lhat{u}_j}{\Lhat{u}_j}$ to account for the sign of the inner product, and we have a right multiply of the metric $\metric$.
But notice that \eqref{eq:rproj} reduces to \eqref{eq:oproj} when the metric is the identity (and thus all inner products are positive.
This projection operator has the property that, for any $(d\plus1)$-vector $w$, the vector $\Pi_\mathscr{T}\,w$ will lie in the subspace $\mathscr{T}$ spanned by the $n$ original $(d\plus1)$-vectors $v_j$ that were orthogonalized.

If you have a full set of $n=d+1$ linearly independent $(d\plus1)$-vectors $v_j$, they will span the whole $(d\plus1)$-dimensional space, and the projection operator $\Pi_\mathscr{T}$ will become the identity $I_{d\plus1}$.
That is, if you have an orthonormal basis of $d+1$ unit vectors $\Lhat{u}_j$
\begin{align}
    I_{d\plus1} &= \sum_{j=1}^{d+1} \frac{\Lhat{u}_j\,\Lhat{u}_j^\top\metric}{\inner{\Lhat{u}_j}{\Lhat{u}_j}} = \sum_{j=1}^{d+1} \frac{\Lvec{u}_j\,\Lvec{u}_j^\top\metric}{\inner{\Lvec{u}_j}{\Lvec{u}_j}} ~,
\end{align}
where we have written it in terms of both the normalized and un-normalized orthogonal vectors; note that $\inner{\Lhat{u}_j}{\Lhat{u}_j}=\pm 1$.
In quantum-mechanics (braket) notation, this expression for the identity becomes a standard formula in quantum mechanics:
\begin{align}
    I_{d\plus1} &= \sum_{j=1}^{d+1} \ketbra{\Lhat{u}_j}{\Lhat{u}_j}
    \\
    \ket{\Lhat{u}_j} &\equiv \Lhat{u}_j\label{eq:Lket}
    \\
    \bra{\Lhat{u}_j} &\equiv \frac{1}{\inner{\Lhat{u}_j}{\Lhat{u}_j}}\,\Lhat{u}_j^\top\metric ~,\label{eq:Lbra}
\end{align}
where we have taken some liberties in defining the bra $\bra{\Lhat{u}_j}$, and we remind you that $\inner{\Lhat{u}_j}{\Lhat{u}_j}=\pm 1$.

Because the metric is its own inverse, if we right-multiply by the metric, we make a simple expression for the metric $\metric$ in terms of the basis vectors:
\begin{align}
    \metric &= \sum_{j=1}^{d+1} \frac{\Lhat{u}_j\,\Lhat{u}_j^\top}{\inner{\Lhat{u}_j}{\Lhat{u}_j}} = \sum_{j=1}^{d+1} \frac{\Lvec{u}_j\,\Lvec{u}_j^\top}{\inner{\Lvec{u}_j}{\Lvec{u}_j}} ~.
\end{align}
This expression is beautifully independent of the signature of the metric (mentioned in \secref{sec:notation}); it works for either signature.

\section{Vector-guided Lorentz transformations}\label{sec:lt}

All this work with orthonormal $(d\plus1)$-vectors in special relativity is in the service of making a coordinate-free expression for the Lorentz transformation.
Consider two observers moving through spacetime.
One (unprime) is moving with $(d\plus1)$-vector velocity $\Lvec{u}$ and the other (prime) is moving with $(d\plus1)$-vector velocity $\Lvec{u}'$.
It is a property of any $(d\plus1)$-vector velocity that it is timelike, and that it has norm 1 (it is a unit vector), so we could have called these two $(d\plus1)$-vector velocities $\Lhat{u}$ and $\Lhat{u}'$.
Each of these two observers has a rest frame, and if $\Lvec{u}-\Lvec{u}'\neq 0$, those two rest frames are different.
What are the Lorentz transformations between the two frames?
That is, how do I construct transforms $Q\in$~O($1,d$) that boost $\Lvec{u}$ to make it parallel to $\Lvec{u}'$, and vice versa?

The answer is that we augment the $(d\plus1)$-vector velocity $\Lvec{u}$ with $d$ additional $(d\plus1)$-vectors $\Lvec{v}_2,\Lvec{v}_3,\ldots,\Lvec{v}_{d+1}$, and we augment the $(d\plus1)$-vector velocity $\Lvec{u}'$ with $d$ additional $(d\plus1)$-vectors $\Lvec{v}'_2,\Lvec{v}'_3,\ldots,\Lvec{v}'_{d+1}$.
If you want the Lorentz transformation to have no rotation or reflections, you can set $\Lvec{v}'_k=\Lvec{v}_k$ for all $k\geq 2$.
Then you orthogonalize the unprimed vectors, with the input order $\Lvec{u},\Lvec{v}_2,\ldots,\Lvec{v}_{d+1}$, to get orthonormal basis vectors $\Lhat{u}_1,\Lhat{u}_2,\ldots,\Lhat{u}_{d+1}$, and you orthogonalize the primed vectors, with the input order $\Lvec{u}',\Lvec{v}'_2,\ldots,\Lvec{v}'_{d+1}$, to get orthonormal basis vectors $\Lhat{u}'_1,\Lhat{u}'_2,\ldots,\Lhat{u}'_{d+1}$.
Armed with these orthonormal basis vectors, the Lorentz transformation $Q$ that boosts from the unprimed frame to the primed frame is simply
\begin{align}
    Q &= \sum_{j=1}^{d+1} \frac{\Lhat{u}'_j\,\Lhat{u}_j^\top\metric}{\inner{\Lhat{u}_j}{\Lhat{u}_j}} ~~ \mbox{provided that} ~ \inner{\Lhat{u}'_j}{\Lhat{u}'_j} = \inner{\Lhat{u}_j}{\Lhat{u}_j} ~ \mbox{for all $j$} ~,\label{eq:LT}
\end{align}
where the inner products $\inner{\Lhat{u}_j}{\Lhat{u}_j}$ (which are all either $+1$ or $-1$) take care of the sign issues between timelike and spacelike $\Lhat{u}_j$.
This expression is coordinate-free.
It is also the relativistic (Lorentz) generalization of the rotation--reflection operator in Euclidean space given in \eqref{eq:rotationoperator}.

A few comments about expression $\eqref{eq:LT}$ for the Lorentz Transformation $Q$ could be the following:
The orthogonalization returns one timelike and three spacelike vectors;
provided that these are ordered such that they match; that is, provided that $\inner{\Lhat{u}_k}{\Lhat{u}_k}=\inner{\Lhat{u}'_k}{\Lhat{u}'_k}$ for all $k$, the construction of $Q$ given by \eqref{eq:LT} will be a valid Lorentz transformation.
If the inputs are ordered such that the first input vector ($v_1$ in the orthogonalization procedure) is timelike, the orthogonalization will make the first output unit vector $\Lhat{u}_1$ be timelike.
If the first input vector is a $(d\plus1)$-vector velocity $\Lvec{u}$, then the the first output vector $\Lhat{u}_1$ will be identical to the input vector $\Lvec{u}$, since velocities in $(d\plus1)$ have unit magnitude.
The expression \eqref{eq:LT} is independent of the signature choice (see \secref{sec:notation}).
Finally, direct calculation will show that the expression \eqref{eq:LT} for $Q$ satisfies the definition \eqref{eq:lore2} of a Lorentz transformation.

\begin{figure}[t]
\begin{mdframed}
\includegraphics[width=\figurewidth]{L_v.png}%
\includegraphics[width=\figurewidth]{L_vp.png}%
\includegraphics[width=\figurewidth]{L_Q.png}
\caption{A demonstration of orthogonalization and rotation in Lorentz $1\plus1$-dimensional space O(1,1).
The time coordinate (the first coordinate) is plotted on the vertical axis and the space coordinate (the second coordinate) is plotted on the horizontal axis.
\textsl{Left:} Two $(1\plus1)$-vectors $\Lvec{v}_1, \Lvec{v}_2$ and the corresponding orthonormal vectors $\Lhat{u}_1, \Lhat{u}_2$ obtained by the orthogonalization procedure.
Note that orthonormal vectors in $1\plus1$ neither look orthogonal nor normalized to the eye; the diagonal lightlike (null) lines are plotted to show that orthogonal $(1\plus1)$-vectors are reflected across null lines.
\textsl{Middle:} A different two $(1\plus1)$-vectors $\Lvec{v}'_1, \Lvec{v}'_2$ and the corresponding orthonormal vectors $\Lhat{u}'_1, \Lhat{u}'_2$.
\textsl{Right:} The action of the transformation operator (Lorentz transform) $Q$ generated from the orthonormal pairs $\Lhat{u}_1, \Lhat{u}_2$ and $\Lhat{u}'_1, \Lhat{u}'_2$.
The black points transform to the red points under the action of the operator $Q$.
The grey points in between are presented to guide the eye; 
note that they trace out not segments of circles (compare to \figref{fig:Euclid}) but instead segments of hyperbolae.\label{fig:Lorentz}}
\end{mdframed}
\end{figure}
This expression \eqref{eq:LT} is a coordinate-free expression for the Lorentz Transformation, in terms of coordinate basis $(d\plus1)$-vectors.
This is the main contribution of this \documentname.
\figref{fig:Lorentz} illustrates the orthogonalization and the action of the Lorentz transformation so constructed in $(1\plus1)$.

In quantum mechanics (braket and ketbra) notation, the expression for the Lorentz transformation becomes
\begin{align}
    Q &= \sum_{j=1}^{d+1} \ketbra{\Lhat{u}'_j}{\Lhat{u}_j} ~~ \mbox{provided that} ~ \braket{\Lhat{u}'_j}{\Lhat{u}'_j} = \braket{\Lhat{u}_j}{\Lhat{u}_j} ~ \mbox{for all $j$} ~,
\end{align}
where we have defined the bras and kets as in \eqref{eq:Lket} and \eqref{eq:Lbra}.

In detail, any Lorentz transformation can be thought of as being a composition of a boost, a time-reversal, a spatial rotation, and a spatial reflection.
Often when we discuss Lorentz transformations, we want transformations that are boost only.
The procedure above delivers a boost-only transformation when the two lists of $(d\plus1)$-vectors to be orthogonalized are identical except for the first elements, which are both timelike.
Spatial rotations and reflections can be introduced by modifying the two lists of $(d\plus1)$-vectors that follow the first (timelike) elements.
The full discussion of all these options is beyond our scope here.

The oddest kind of Lorentz transformation is one that reverses time time direction.
We don't recommend making such transformations, but they are permitted here.
These can be constructed by multiplying one of the input $(d+1)$-vector velocities (either $\Lvec{u}$ or $\Lvec{u}'$) by $-1$ before starting the orthogonalization.

Finally, a user of this method for constructing the Lorentz transformation, a user who has two $(d\plus1)$-vector velocities $\Lvec{u}$ and $\Lvec{u}'$ and just wants a transformation $Q$, might ask: ``What should I use for the additional $(d\plus1)$-vectors $\Lvec{v}_2$ through $\Lvec{v}_{d+1}$?
Our advice, if nothing else is natural, is to use the $d$ spatial unit vectors $\Lhat{u}_2$ through $\Lhat{u}_{d+1}$ that point along the $d$ spatial coordinate axes in one of the original two frames.
That will always work, and never produce any lightlike vector in the orthogonalization procedure.

\section{Discussion}\label{sec:discussion}

HOGG: Much of this is very mathematical and theoretical.
However, the new parameterization \eqref{eq:LT} of the Lorentz transformation given in \secref{sec:lt} is useful and conceptually valuable.

HOGG: The hacks to fix the orthogonalization in \secref{sec:orth} are unsatisfying. Are there better solutions?

HOGG: Comment on numerical stability: This is an issue in general, but when $d\approx 3$, it isn't a big issue. See ``Modified Gram-Schmidt''.

Everything in this \documentname{}, including the orthogonalization procedure and the outer-product form for the Lorentz transformation, is written for $d\plus1$ spaces, governed by the group O($1,d$).
However, everything also applies in more general $d\plus s$ spaces, governed by O($s,d$).
These kinds of spaces can arise in string-like theories that compactify to $3\plus 1$ for the purposes of our macroscopic world.
SOLE PLZ CHECK:
Our conjecture is that the only difference between $d\plus1$ and $d\plus s$ is that, as $d$ and $s$ both get large, the probability of generating null vectors in the orthogonalization procedure will increase.
This is because the space for null vectors increases---it has dimensionality $\min(s,d)$---that increase of dimensionality increases the chances of obtaining null vectors, both in principle and in practice because of numerical issues.

All the code used to make the figures for this \documentname{} is available under an open-source license at HOGG: URL HERE.

\paragraph{Acknowledgements:}
It is a pleasure to thank
  Roger Blandford (Stanford), and
  Ben Blum-Smith (JHU)
for very valuable discussions.
This research was supported in part by XXX YYY.
The Flatiron Institute is a division of the Simons Foundation.

\raggedright
\printbibliography
\end{document}
