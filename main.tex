% Copyright 2024, 2025 the authors. All rights reserved.

% Style Notes
% -----------
% - The audience is a faculty member who teaches SR to first-year undergraduates.
% - Use $d\plus s$ for an in-text or wordy d+s, and $d+s$ for an in-equation or mathy $d+s$.
% - Don't put hyphens in timelike, spacelike, lightlike (null).
% - Typeset d-vectors and (d+s)-vectors using the macros, not by hand.
% - Use "\quad~" sparingly to make large separations in an equation but almost always use "~".
% - Use \metric and \proj and everything else we have defined.
% - We call it "orthonormalization" not "orthogonalization".
% - Use bras and kets only for unit vectors in d+s; ie, not for non-normalized vectors, and not for Euclidean space.
% - Should I make the figures b/w-safe? Open black points and closed red points?
% - submit to arXiv.

% To-do
% -----
% - Stronger literature searches.
% - Are we happy with what is written about the literature?
% - Can the expressions for the "minimal" rotation and LT be simplified further? 
% - The references are a mess: German or English titles? Order? arXiv entries? Make it not suck.
% - Where to submit? Maybe European Journal of Physics? (Open Access) or American Journal of Physics? (Maybe higher impact?)

\documentclass{article}
\usepackage[utf8]{inputenc}

% linx
\usepackage[hidelinks]{hyperref}

% math definitions
\newcommand{\metric}{\mathsf{H}}
\newcommand{\proj}{\mathsf{\Pi}}
\usepackage{amsmath,amsfonts,mathrsfs}
\DeclareMathOperator{\dd}{d\!}
\newcommand\upvec[1]{\!\vec{\,\mathrm{#1}}}
\newcommand{\Evec}[1]{{\mathbf{#1}}} % d-vector
\newcommand{\Ehat}[1]{{\mathbf{\hat{#1}}}} % d-vector unit vector
\newcommand{\Lvec}[1]{\upvec{\mathsf{#1}}} % (d+s)-vector
\newcommand{\Lhat}[1]{\hat{\mathsf{#1}}} % (d+s)-vector unit vector
\newcommand{\Lblank}[1]{\mathsf{#1}} % (d+s)-vector unit vector
\newcommand{\bra}[1]{\langle\,{#1}\,|}
\newcommand{\ket}[1]{|\,{#1}\,\rangle}
\newcommand{\braket}[2]{\langle\,{#1}\,|\,{#2}\,\rangle}
\newcommand{\ketbra}[2]{|\,{#1}\,\rangle\,\langle\,{#2}\,|}
\newcommand{\plus}{\!+\!} % evil

% fixing latex page layout and typography
\usepackage[letterpaper]{geometry}
\setlength{\textwidth}{5.50in}
\setlength{\textheight}{9.40in}
\setlength{\oddsidemargin}{3.25in}
\addtolength{\oddsidemargin}{-0.5\textwidth}
\setlength{\topmargin}{-0.55in}
\renewcommand{\small}{\normalsize} % pure evil
\linespread{1.08}
\frenchspacing\raggedbottom\sloppy\sloppypar
\pagestyle{myheadings}
\markboth{}{\textsf{Hogg \& Villar / Coordinate-free parameterization for all Lorentz transformations}}
\newcommand{\documentname}{\textsl{Note}}
\newcommand{\secref}[1]{Section~\ref{#1}}
\newcommand{\figref}[1]{Figure~\ref{#1}}

% figure boxes and figure layout
\usepackage{graphicx}
\graphicspath{{./notebooks/}}
\usepackage[framemethod=tikz]{mdframed}
\usetikzlibrary{shadows}
\definecolor{captiongray}{HTML}{555555}
\mdfsetup{%
  innertopmargin=2ex,
  innerbottommargin=1.8ex,
  linecolor=captiongray,
  linewidth=0.5pt,
  roundcorner=1pt,
  shadow=false,
  %shadowcolor=black!05,
  %hadowsize=4pt
}
\newlength{\figurewidth}
\setlength{\figurewidth}{0.315\textwidth}
\setlength{\floatsep}{1ex}
\setlength{\textfloatsep}{1ex}

\title{\bfseries A coordinate-free parameterization of all Lorentz transformations in all spacetimes}
\author{\textbf{David W. Hogg}\footnote{DWH is in the Center for Cosmology and Particle Physics, Department of Physics, New York University, and in the Max Planck Institute for Astronomy, and in the Center for Computational Astrophysics, Flatiron Institute. Send email to \texttt{<david.hogg@nyu.edu>}.}
        \and
        \textbf{Soledad Villar}\footnote{SV is in the Department of Applied Mathematics and Statistics, Johns Hopkins University, and in the Mathematical Institute of Data Science, Johns Hopkins University, and in the Center for Computational Mathematics, Flatiron Institute.}}
\date{2025 January}

\begin{document}\thispagestyle{plain}
\maketitle

\begin{abstract}\noindent % don't use \plus or other macros in the abstract
    Special and general relativity in $d+s$ spacetime dimensions (our macroscopic Universe is $3+1$) are metric theories with a metric that isn't positive definite, such that timelike, lightlike (null), and spacelike vectors have positive, zero, and negative inner products with themselves.
    Orthonormalization of vectors works in these theories; it can be used to make a coordinate basis ($d+s$ orthogonal unit vectors, $s$ timelike and $d$ spacelike) out of (almost) any collection of $d+s$ linearly independent input vectors.
    Given two such bases, the Lorentz transformation that goes from one of the two bases to the other can be constructed with a simple outer-product form, analogous to a sum over ket-bras in Dirac notation.
    We thereby present a new coordinate-free parameterization of all possible Lorentz transformations for all $d+s$ spacetimes.
\end{abstract}

\section{Introduction}\label{sec:intro}

Special relativity \cite{sr} is a purely kinematic theory, which can be formulated in terms of vector displacements between \emph{events}.
These vector displacements are 4-vectors in $(3\plus1)$-dimensional spacetime, which has three spatial dimensions and one time dimension.
The coordinate system can be varied not just by rotations and translations, but also by \emph{boosts}, in which the stationary observer (or equivalently the zero-point of 3-vector velocity) is redefined.
Most of the remarkable and counter-intuitive aspects of special relativity---time dilation, length contraction, twin paradox, and so on---flow from the fact that boost transformations preserve not the usual vector magnitudes and inner products, but instead magnitudes and inner products made with a \emph{non-positive-definite metric tensor}\footnote{For some, you can't call something a ``metric tensor'' if it isn't positive definite: How can you use a metric to define displacements if those displacements won't satisfy the triangle inequality? But that's where we are.}.
General relativity~\cite{gr} is a dynamical theory in which the non-positive-definite spacetime metric becomes (in general) a function of space and time, and the resulting curvature of spacetime is related to the energy densities and stresses in the matter and fields.
This \documentname{} is motivated partly by attempts to understand the local, geometric properties of spacetime---we will focus on special relativity---and to confront a few of the pathologies that arise.

For group theorists, $(3\plus1)$-dimensional special relativity is equivariant with respect to the group called the Lorentz group and denoted O($1,3$).
In ($d\plus1$)-dimensional spacetime the group is O($1,d$).
The operators in the group O($1,d$) include rotations in the $d$-dimensional spatial subspace of spacetime, reflections in space and time, and boosts. %HOGG explain boosts in a sentence.
And then there are groups with \emph{multiple times}, such that it is $(d\plus s)$-dimensional spacetime and the group is O($s,d$).
When there are multiple times, the operators include rotations in the time sector as well as rotations in the spatial sector.
All these spacetimes and groups are generalizations of Euclidean space and the orthogonal group O($d$), which is the group of rotations and reflections in $d$-dimensional space.
In the context of group theory, the word ``equivariant'' means the following:
If you rotate, reflect, or boost the space, all of the predictions of the theory rotate, reflect, and boost appropriately to match.
What group theorists call ``equivariance'', physicists call ``covariance'' or ``symmetry''.

As a point of motivation, we got interested in the questions addressed in this paper through our work on invariant and equivariant machine-learning methods \cite{scalars}.
In this work, we considered several classical Lie groups, including the Lorentz group.
We noticed that there are pathologies in the Lorentz group associated with orthogonal vectors (such that a vector can be orthogonal to itself, for instance).

In some sense, the discovery of special relativity was the beginning of the discovery that physics can be stated in a coordinate-free form.
That is, one does not need to specify a coordinate system in order to explain the physical behavior of a system.
Sometimes a coordinate system is useful.
But it is usually not \emph{required}.
In the special-relativity literature, the Lorentz transformations are almost always expressed in a particular coordinate system, aligned with the boost direction (see, eg, \cite{french, zakamska} or just about any other textbook on the subject)
Here we develop completely coordinate-free expressions for these operators in special relativity; our expressions depend on the change of velocity or orientation between the two frames, but not on the coordinate system in which these are expressed.

\paragraph{Our contributions:}
\begin{itemize}
\item
We spell out the relationship between orthonormalization, projection, and rotation in Euclidean space and their relativistic equivalents (equivalents in Minkowski or Lorentz spacetime).
The only substantial differences are the inclusion of the metric tensor $\metric$ in relevant places, and that there are some cases in which the orthonormalization procedure produces lightlike vectors (and thus borks).
\item
We use the output of the orthonormalization to produce (in \secref{sec:lt}) a new parameterization or new form for the Lorentz transformation, which transforms the coordinates of events between two reference frames.
This form is based on outer products of basis vectors (or, in Dirac notation, ket--bras).
This new form is coordinate-free, created directly out of the coordinate-basis unit vectors describing the two frames.
It is analogous to a particular coordinate-free form for a Euclidean rotation matrix, but with modifications to account for the non-positive-definite properties of the metric; it works for all $d\plus s$ spacetimes.
\item
We additionally deliver (in \secref{sec:lt}) a more restricted coordinate-free form for the Lorentz transformation that can produce a pure boost given as input the two velocity vectors indicating the velocities of the two rest frames connected by the boost.
\end{itemize}

\paragraph{Prior work:}
Some of the ideas discussed here have been looked at previously.
In particular, orthonormalization in special relativity is mentioned in~\cite{joot}, which also thinks about different frames in terms of basis vectors produced by orthonormalization.
Coordinate-free Lorentz transformations are partially developed in~\cite{wagner}, but with a very different notation (in terms of 3-vectors, not 4-vectors) and a very different set of goals, part of a bigger program of describing all of special relativity in coordinate-free form.
Neither of these previous investigations develops the outer-product (or ket--bra) forms we show below, nor do they address any geometries beyond $3\plus 1$.
Another relevant investigation decomposes the Lorentz transformation into orthogonal bivector expressions \cite{hanson}.
This latter work is also specialized to $3+1$, but it would generalize straightforwardly.

All that said, we emphasize that the orthonormalization we show below is not in any sense new:
Gram--Schmidt orthonormalization works in any inner-product space, and special relativity (or general relativity, considered in a local neighborhood) provides an inner product space.
Similarly, writing rotation or other transformation operators as sums of outer products is not in any sense new:
This is one of the natural coordinate-free forms for such operators, and was elucidated by, for example, Dirac \cite{dirac}, among many others.

\section{Review of operations in Euclidean spaces}\label{sec:od}

Before we consider special relativity, it is worth reviewing how an orthonormalization is performed, and how projection and rotation--reflection operators are constructed, in ordinary Euclidean space with an ordinary Euclidean metric.
In standard $d$-dimensional space, with the standard Euclidean metric (the identity), containing vectors governed by the standard orthogonal group O($d$), inner products (scalar products) of vectors are defined as follows:
Given two column vectors $\Evec{u},\Evec{v}\in\mathbb{R}^d$ (or, more specifically, $\mathbb{R}^{d\times1}$), the inner product (or scalar product) is defined as
\begin{align}
    \Evec{u}^\top \Evec{v} &= \Evec{v}^\top \Evec{u} ~.
\end{align}
Two vectors $\Evec{u},\Evec{v}$ are considered orthogonal if their inner product vanishes, or $\Evec{u}^\top\Evec{v}=0$.
In Euclidean space, we will call these vectors ``$d$-vectors'' and typeset them bold.

Imagine that we are given a collection of $n$ linearly independent $d$-vectors $\Evec{a}_1,\Evec{a}_2,\ldots,\Evec{a}_n$,
and we want to construct orthonormal basis vectors $\Ehat{u}_1,\Ehat{u}_2,\ldots,\Ehat{u}_n$ that span the linear subspace spanned by the vectors $\Evec{v}_j$.
We can perform this orthonormalization by the Gram--Schmidt process \cite{gram, schmidt}:
We sequentially construct orthogonal vectors $\Evec{u}_1,\Evec{u}_2,\ldots,\Evec{u}_n$ and normalize them into orthogonal unit vectors $\Ehat{u}_1,\Ehat{u}_2,\ldots,\Ehat{u}_n$ by the following algorithm:
\begin{align}
    \Evec{u}_1 &\leftarrow \Evec{a}_1 \label{eq:ogs1}
    \\
    \mbox{then for each $j$ ($2\leq j\leq n$) in order:} \quad~ \Evec{u}_j &\leftarrow \Evec{a}_j - \sum_{k=1}^{j-1} \frac{\Evec{a}_j^\top\Evec{u}_k}{\Evec{u}_k^\top\Evec{u}_k}\,\Evec{u}_k \label{eq:ogs2}
    \\
    \mbox{then for each $j$ ($1\leq j\leq n$):} \quad~ \Ehat{u}_j &\leftarrow \frac{1}{\sqrt{\Evec{u}_j^\top\Evec{u}_j}}\,\Evec{u}_j ~. \label{eq:ogs3}
\end{align}
Note that the procedure in \eqref{eq:ogs2} is order-dependent: If you put the $d$-vectors $\Evec{a}_1,\Evec{a}_2,\ldots,\Evec{a}_n$ into a different order, the orthonormalization will return different specific basis unit vectors $\Ehat{u}_1,\Ehat{u}_2,\ldots,\Ehat{u}_n$.
However, all the different possible returned bases (under permutations of the $\Evec{v}_j$) will span the same $n$-dimentional linear subspace of the $d$-dimentional space.

The reader might be concerned that the orthonormalization involves division by forms like $\sqrt{\Evec{u}^\top\Evec{u}}$.
Provided that the input vectors are nonzero and linearly independent, this divisor will never vanish.
That situation will change when we consider the relativistic case in \secref{sec:orth}.

If you have $n\leq d$ linearly independent $d$-vectors $\Evec{v}_j$ that span an $n$-dimensional subspace $\mathscr{S}$ of the $d$-dimensional space, you can use this orthonormalization procedure to build a subspace projection operator $\proj_\mathscr{S}$
\begin{align}\label{eq:oproj}
    \proj_\mathscr{S} &= \sum_{j=1}^n \Ehat{u}_j\,\Ehat{u}_j^\top ~,
\end{align}
where the $\Ehat{u}_j$ are the orthogonal unit vectors\footnote{Note that because---for us---all vectors $\Evec{u},\Evec{v}$ are column vectors, $\Evec{u}\,\Evec{v}^\top\in\mathbb{R}^{d\times d}$ while $\Evec{u}^\top \Evec{v}\in\mathbb{R}$.} delivered by the orthonormalization procedure applied to the $\Evec{a}_j$.
This projection operator has the property that, for any vector $\Evec{b}\in\mathbb{R}^d$, the vector $\proj_\mathscr{S}\,\Evec{b}$ will lie in the subspace spanned by the $\Evec{a}_j$.
The projection operator $\proj_{\mathscr{S}^\perp}$ into the complementary subspace $\mathscr{S}^\perp$ is then just
\begin{align}\label{eq:oprojcomp}
    \proj_{\mathscr{S}^\perp} &= I_d - \proj_\mathscr{S} ~,
\end{align}
where $I_d$ is the $d\times d$ identity.
One consequence of this line of reasoning is that if you have $n=d$ linearly independent vectors $\Evec{a}_j$, they will span the whole space, and the projection operator $\proj_\mathscr{S}$ will become the identity $I_d$.
That is, if you have an orthonormal basis of $d$ unit vectors $\Ehat{u}_j$, then
\begin{align}\label{eq:oI}
    I_d &= \sum_{j=1}^d \Ehat{u}_j\,\Ehat{u}_j^\top ~.
\end{align}
Physicists might call these forms for $\proj_\mathscr{S}$ and $I_d$ \emph{coordinate-free}:
They are coordinate-free in the sense that they are stated just in terms of the input vectors, not in terms of vector or matrix components.
Or, equivalently, we didn't have to specify our coordinate system when we constructed them; we only had to specify the vectors that span the subspace.

It is also possible to write any rotation--reflection operator $R$ in a coordinate-free form.
First a definition: A matrix $R\in\mathbb{R}^{d\times d}$ is a rotation--reflection operator in the orthogonal group O($d$) if the operator preserves all inner products (scalar products).
That is,
\begin{equation}
    R \in \mbox{O($d$)} ~ \mbox{iff} ~ \Evec{u}^\top\Evec{v}=(R\,\Evec{u})^\top(R\,\Evec{v}) ~ \mbox{for all $\Evec{u},\Evec{v}$ in $\mathbb{R}^d$} ~.\label{eq:orth1}
\end{equation}
This, in turn, will be true if and only if $R$ is a square root of the identity:
\begin{equation}
    R \in \mbox{O($d$)} ~ \mbox{iff} ~ R^\top R=I_d ~.\label{eq:orth2}
\end{equation}
We call $R$ a rotation--reflection operator because the group encompasses all rotations, all reflections, and all combinations of rotations and reflections.

For example, the simplest (interesting) orthogonal space is O($2$). In this case the operators form a one-dimensional family; they are all of the form
\begin{align}
    R &= \begin{bmatrix}\cos{\theta} & -\sin{\theta} \\ \sin{\theta} & \cos{\theta}\end{bmatrix} ~\mbox{or}~
    \begin{bmatrix}-\cos{\theta} & \sin{\theta} \\ \sin{\theta} & \cos{\theta}\end{bmatrix} \label{eq:o2}
    \\
    -\pi &< \theta < \pi ~, \nonumber
\end{align}
where $\theta$ is a rotation angle.
The two choices in \eqref{eq:o2} correspond to, in one case, pure rotation and, in the other, rotation plus reflection.
When $d>2$ the coordinate representations of the $R$ become large matrices full of trig functions.
They get very complicated, while the coordinate-free representations we are about to deliver stay simple.

Now how do we construct general coordinate-free forms for the operators $R$?
Imagine that we have two complete orthonormal bases in $\mathbb{R}^d$, $\Ehat{u}_1,\Ehat{u}_2,\ldots,\Ehat{u}_d$ and $\Ehat{v}_1,\Ehat{v}_2,\ldots,\Ehat{v}_d$.
We can now imagine a rotation--reflection operator $R$ that rotates and reflects any $d$-vector $\Evec{w}$ in the same way that these two bases are rotated and reflected with respect to one another.
This particular operator $R$ can be constructed by the following coordinate-free outer-product construction:
\begin{align}
    R &= \sum_{j=1}^d \Ehat{v}_j\,\Ehat{u}_j^\top ~.\label{eq:rotationoperator}
\end{align}
That is, rotations and reflections can be specified directly using orthonormal bases, with no explicit reference to any angles or coordinates.
In this sense, this form could be thought of as a ``vector-guided'' rotation matrix:
It is constructed directly from the vectors, and independent of how those vectors are represented.
It is therefore coordinate-free.

Finally, there is an expression for the rotation operator $R$ that rotates a vector through the angle betweeen unit vector $\Ehat{u}$ and unit vector $\Ehat{v}$ in the plane defined by $\Ehat{u}$ and $\Ehat{v}$; that is, the smallest-angle rotation operator that takes $\Ehat{u}$ to $\Ehat{v}$.
This is
\begin{align}
    R &= \Ehat{v}\,\Ehat{u}^\top - \Ehat{u}\,\Ehat{v}^\top + (\Ehat{u}^\top\Ehat{v})\,\proj_{uv} + \proj_{uv^\perp} \label{eq:vecs2rot} \\
    \proj_{uv} &= \frac{[\Ehat{u}\,\Ehat{u}^\top + \Ehat{v}\,\Ehat{v}^\top] - (\Ehat{u}^\top\Ehat{v})\,[\Ehat{u}\,\Ehat{v}^\top + \Ehat{v}\,\Ehat{u}^\top]}{1 - (\Ehat{u}^\top\Ehat{v})^2} ~,
\end{align}
where $\proj_{uv}$ is the projection operator that projects onto the subspace spanned by $\Ehat{u}$ and $\Ehat{v}$, and $\proj_{uv^\perp} = I_d - \proj_{uv}$ is the complementary projection operator.
% \HOGG{SOLE: Can you check this expression (a) is it a rotation (is it a square root of the identity with determinant $+1$), and (b) does it rotate u to v?}
This is a useful expression when you aren't given two complete coordinate bases, but instead just the two directions that define the endpoints of the rotation; it will generalize usefully to the relativistic case.

\begin{figure}[t]
\begin{mdframed}
\includegraphics[width=\figurewidth]{E_v.png}%
\includegraphics[width=\figurewidth]{E_vp.png}%
\includegraphics[width=\figurewidth]{E_Q.png}
\caption{A demonstration of orthonormalization and rotation in Euclidean 2-dimensional space O($2$).
\textsl{Left:} Two 2-vectors $\Evec{a}_1, \Evec{a}_2$ and the corresponding orthonormal 2-vectors $\Ehat{u}_1, \Ehat{u}_2$ obtained by the orthonormalization procedure.
The unit circle is shown to indicate the locus of (the tips of) normalized 2-vectors.
\textsl{Middle:} A different two 2-vectors $\Evec{b}_1, \Evec{b}_2$ and the corresponding orthonormal 2-vectors $\Ehat{v}_1, \Ehat{v}_2$.
\textsl{Right:} The action of the rotation operator $R$ generated from the orthonomal pairs $\Ehat{u}_1, \Ehat{u}_2$ and $\Ehat{v}_1, \Ehat{v}_2$.
The black points rotate to the red points under the action of the operator $R$.
The grey points in between are presented to guide the eye.\label{fig:Euclid}}
\end{mdframed}
\end{figure}
The result of orthonormalization of two pairs of 2-vectors in O($2$) ($d=2$) is shown in \figref{fig:Euclid}.
Also shown in \figref{fig:Euclid} is the action of the rotation operator $R$ derived from the basis vectors generated by those two orthonormalizations.

\section{Relativistic notation and transformations}\label{sec:notation}

There is a history of notation in special and general relativity.
Here we deliver a translation from traditional Einstein summation notation, and traditional language about boost, to more linear-algebra-oriented notations.
After this Section, we will be using exclusively linear-algebra and Dirac notations, which are simpler (for us).

In Lorentz or Minkowski space, we think of there being a metric $\metric$ (often called $g^{\mu\nu}$ or $\eta^{\mu\nu}$ or $\eta$), which is a $(d+s)\times(d+s)$ matrix that is \emph{not} positive definite.
The metric $\metric$ is diagonal with $+1$ in the first $s$ diagonal positions and $-1$ repeated on all the remaining $d$ diagonal elements.
In $3\plus1$ this is
\begin{align}\label{eq:sig}
    \metric &= \begin{bmatrix}1 & 0 & 0 & 0\\
                              0 & -1 & 0 & 0\\
                              0 & 0 & -1 & 0\\
                              0 & 0 & 0 & -1\end{bmatrix} ~.
\end{align}
There is another possible signature---with $-1$ in the first $s$ positions and $+1$ thereafter.
In this \documentname{} we choose the signature illustrated in \eqref{eq:sig}; nothing significant in our discussion changes if you choose the opposite signature.
Indeed, this is one of the main reasons to pursue a coordinate-free formulation of special relativity:
The coordinate-free representations don't care about the signature of your metric, or any other aspects of your coordinate system.\footnote{It is precisely because the choice of signature doesn't matter that physicists will constantly argue about it. We don't know many physicists who don't have a strong opinion about the signature. We ourselves have no strong opinion, and our expressions are agnostic to the signature.}
The signature of the metric will only come up in our definitions of ``timelike'' \eqref{eq:timelike}, ``lightlike'' \eqref{eq:lightlike}, and ``spacelike'' \eqref{eq:spacelike} below.

We are going to consider vectors $\Lvec{a}, \Lvec{b}, \Lvec{u}, \Lvec{v}\in\mathbb{R}^{(d+s)}$ in Lorentz space or Minkowski space or spacetime.
We will call these vectors ``($d\plus s$)-vectors'', and typeset them sanserif with hats (arrows or carets, depending).

Old-school relativists tend to write the relativistic inner product (the scalar product or Minkowski inner product) between two ($d\plus s$)-vectors $\Lvec{u}$ and $\Lvec{v}$ as
\begin{align}
    \Lblank{u}^\mu\,\Lblank{v}_\mu &= \Lblank{v}^\mu\,\Lblank{u}_\mu ~,
\end{align}
where $\mu$ is a component index (such that $\Lblank{u}_\mu$ is the $\mu$th component of $\Lvec{u}$) with $1\leq\mu\leq d+s$, and the repeated index is (implicitly) summed\footnote{%
In these expressions, greek indexes like $\mu$, $\nu$ are be indexes over vector components (going from 1 to 4 in $3\plus1$, for example), and (later) roman indexes like $i$, $j$, $k$ will be indexes over vectors or other things.} .
The $\Lblank{u}^\mu$ is a contravariant vector component and the $\Lblank{v}_\mu$ is a covariant vector component.
Contravariant and covariant components are related as follows:
\begin{align}
    \Lblank{u}^\mu &= \metric^{\mu\nu}\,\Lblank{u}_\nu \equiv \sum_{\nu=1}^{d+s} \metric^{\mu\nu}\,\Lblank{u}_\nu
    \\
    \Lblank{u}^\mu\,\Lblank{v}_\mu &= \metric^{\mu\nu}\,\Lblank{u}_\mu\,\Lblank{v}_\nu \equiv \sum_{\mu=1}^{d+s}\sum_{\nu=1}^{d+s} \metric^{\mu\nu}\,\Lblank{u}_\mu\,\Lblank{v}_\nu
\end{align}
where the $\metric^{\mu\nu}$ are the components of the metric $\metric$.
The implicit summations on the left of the ``$\equiv$'' signs are guided by the rules of what's called Einstein summation notation (\cite{summation}; it is a particular case of the Ricci calculus~\cite{ricci}): Indexes can appear exactly once or exactly twice (and no more) and when they appear twice, one must be up and one must be down, and they are summed from 1 to $d+s$.

In linear algebra notation, if we think of $\Lvec{u}$ and $\Lvec{v}$ as being column vectors in $\mathbb{R}^{d+s}$ (or, to be extremely specific, $\mathbb{R}^{(d+s)\times 1}$), then we can write this same inner product as
\begin{align}\label{eq:inner}
    \Lvec{u}^\top\metric\,\Lvec{v} &= \Lvec{v}^\top\metric\,\Lvec{u} ~.
\end{align}
We are going to use this notation going forward, not the Einstein summation notation.

What, physically, are the ($3\plus 1$)-vectors of special relativity?
Events in spacetime are represented by one time coordinate and three spatial coordinates (a position); they are things that happened at some place and time.
In $d\plus s$, events have $s$ time coordinates and $d$ spatial coordinates.
The displacement $\Lvec{s}$ between two such events is a ($d\plus s$)-vector.
In $d\plus s$ spacetime there are generalizations of many standard $d$-vectors to which you are accustomed.
For example,
the ($d\plus s$)-vector velocity $\Lvec{u}$ is a timelike vector with $\Lvec{u}^\top\metric\,\Lvec{u}=1$ (a unit vector), where the spatial part of $\Lvec{u}$ (the last $d$ components) is proportional to what is traditionally the $d$-vector velocity.
In $d+s=3+1$ dimensions the ($3\plus1$)-vector velocity $\Lvec{u}$ is given by
\begin{align}
    \Lvec{u}^\top &= \begin{bmatrix} \gamma & \gamma\,\beta_x & \gamma\,\beta_y & \gamma\,\beta_z \end{bmatrix} \\
    \gamma &= (1 - \beta_x^2 - \beta_y^2 - \beta_z^2)^{-1/2} \nonumber\\
    \begin{bmatrix} \beta_x & \beta_y & \beta_z\end{bmatrix} &= \begin{bmatrix}\displaystyle\frac{1}{c}\,\frac{\dd x}{\dd t} & \displaystyle\frac{1}{c}\,\frac{\dd y}{\dd t} & \displaystyle\frac{1}{c}\,\frac{\dd z}{\dd t} \end{bmatrix} = \frac{1}{c}\,\Evec{v}^\top ~,\nonumber
\end{align}
where the transposes on $\Lvec{u}$ and $\Evec{v}$ are reminders that vectors are (for us) always column vectors,
$c$ is the speed of light in a vacuum (or the speed of lightlike or null trajectories),
and the $\beta_k$ are the components of a dimensionless 3-vector velocity $\Evec{v}/c$.
Explicit calculation demonstrates that $\Lvec{u}^\top\metric\,\Lvec{u}=1$ (in this signature) for all settings of $\Evec{v}/c$.
Another ($d\plus1$)-vector example\footnote{We say ``$d+1$'' here and not ``$d+s$'' because we don't know how the momentum generalizes to the case of multiple times.} is the ($d\plus1$)-vector momentum $\Lvec{p}$ of a particle.
This is a timelike vector with $\Lvec{p}^\top\metric\,\Lvec{p}=m^2\,c^4$, where $m$ is the rest mass of the particle.
The ($d\plus1$)-vector momentum has the energy $E / c$ of the particle as its first component (the time component), and the Euclidean $d$-vector momentum $\Evec{p}$ in its remaining $d$ components.\footnote{%
If you write out the inner product $\Lvec{p}^\top\metric\,\Lvec{p}$ for the ($d\plus1$)-vector momentum $\Lvec{p}$, you get $$E^2 - (\Evec{p}^\top\Evec{p})\,c^2 = m^2\,c^4~,$$ where $\Evec{p}$ is the $d$-vector (spatial) momentum. In the rest frame, the $d$-vector momentum vanishes and this becomes $E=m\,c^2$. This is the equation that made Einstein famous.}

When you change reference frames or coordinate systems, a Lorentz transformation is applied.
Under the Lorentz transformation, the components of all of the ($d\plus s$)-vectors will change, but all the inner products among them (and with themselves) will remain the same.

In standard special-relativity lore, Lorentz transformations are taught as \emph{boosts} in which the assignment of the stationary (or zero-velocity) observer is changed and the time and space axes change accordingly.
For our purposes, the Lorentz transformations also include spatial rotations, spatial reflections, and even time reflections (gasp!):
That is, for our purposes, an operator $Q$ is a valid Lorentz transformation if it is a member of the Lorentz group O($s,d$).
To be more specific, an operator $Q$ (which can be thought of as a $(d+s)\times(d+s)$ matrix) is a Lorentz transformation---is an operator in the group O($s,d$)---if it preserves all inner products (scalar products). 
That is,
\begin{equation}
    Q \in \mbox{O($s,d$)} ~ \mbox{iff} ~ \Lvec{u}^\top\metric\,\Lvec{v}=(Q\,\Lvec{u})^\top\metric\,(Q\,\Lvec{v}) ~ \mbox{for all $\Lvec{u},\Lvec{v}$ in $\mathbb{R}^{d+s}$} ~.\label{eq:lore1}
\end{equation}
This, in turn, will be true if and only if $Q$ leaves the metric unchanged:
\begin{equation}
    Q \in \mbox{O($s,d$)} ~ \mbox{iff} ~ Q^\top\metric\,Q=\metric ~.\label{eq:lore2}
\end{equation}
This is our (surprising, perhaps) definition of the Lorentz transformation $Q$.
Note how similar the Lorentz-group statements \eqref{eq:lore1} and \eqref{eq:lore2} are to the orthogonal-group statements \eqref{eq:orth1} and \eqref{eq:orth2}.
In a sense, group elements $Q$ are square roots of the metric $\metric$.

For example, the simplest non-trivial Lorentz space is O($1,1$) or $1\plus1$ ($s=d=1$).
In this case, the Lorentz transformations form a one-dimensional family; they are all of the form
\begin{align}
    Q &= \begin{bmatrix}\gamma & \beta\,\gamma \\ \beta\,\gamma & \gamma\end{bmatrix} ~\mbox{or}~
    \begin{bmatrix}-\gamma & -\beta\,\gamma \\ \beta\,\gamma & \gamma\end{bmatrix} ~\mbox{or}~
    \begin{bmatrix}\gamma & \beta\,\gamma \\ -\beta\,\gamma & -\gamma\end{bmatrix}  ~\mbox{or}~
    \begin{bmatrix}-\gamma & -\beta\,\gamma \\ -\beta\,\gamma & -\gamma\end{bmatrix} \label{eq:o11}
    \\
    \gamma &\equiv \frac{1}{\sqrt{1 - \beta^2}} ~ \mbox{and} ~ -1 < \beta < 1 ~.\nonumber
\end{align}
In this simple case, $\beta$ is the dimensionless velocity of the boost, and $\gamma$ is the Lorentz factor.
The four choices in \eqref{eq:o11} correspond to even parity, reversing time, reversing space, and reversing both.\footnote{%
Many physicists would not permit reversals of time or space among the Lorentz transformations.
These reversals appear inevitably when we define the set of Lorentz transformations to be all the operators $Q$ such that $\metric=Q^\top\metric\,Q$, as we do.
So we depart here slightly from standard practice by being maximally inclusive.}
But in what follows we are going to develop \emph{coordinate-free forms} for the Lorentz transformations, in analogy to the coordinate-free forms for the rotation--reflection operators given in \secref{sec:od}.

Finally we remark that---because the metric is non-positive-definite---a nonzero ($d\plus s$)-vector $\Lvec{v}$ can come in three forms, \emph{timelike}, \emph{spacelike}, or \emph{lightlike} (sometimes \emph{null}):
\begin{align}
    \Lvec{v} ~ \mbox{is timelike}  &~ \mbox{if} ~ \Lvec{v}^\top\metric\,\Lvec{v} > 0 \label{eq:timelike}\\
    \Lvec{v} ~ \mbox{is lightlike} &~ \mbox{if} ~ \Lvec{v}^\top\metric\,\Lvec{v} = 0 \label{eq:lightlike}\\
    \Lvec{v} ~ \mbox{is spacelike} &~ \mbox{if} ~ \Lvec{v}^\top\metric\,\Lvec{v} < 0 ~.\label{eq:spacelike}
\end{align}
Technically, these definitions depend on the signature you chose for your metric; you would use the opposite language if you chose the opposite signature.
This is the only point in this \documentname{} that depends on the signature; everything else is agnostic to signature.
Because Lorentz transformations $Q\in\mbox{O($s,d$)}$ preserve inner products, you can't Lorentz transform a vector from any one of these three categories (timelike, lightlike, or spacelike) to any other of these categories; the category (timelike, lightlike, or spacelike) is a Lorentz invariant property of the ($d\plus s$)-vector.
This all relates to the causal structure of spacetime, which is out of scope here.

\section{Relativistic orthonormalization}\label{sec:orth}

In $d\plus s$ spacetime we will still say that two ($d\plus s$)-vectors are ``orthogonal'' if their inner product is zero.
\begin{align}
    \Lvec{u},\Lvec{v} ~ \mbox{are orthogonal iff} ~ \Lvec{u}^\top\metric\,\Lvec{v}=0 ~,
\end{align}
where the inner product is defined as in \eqref{eq:inner}.
This is great, but it leads to a strange consequence:
Any lightlike vector $\Lvec{v}$ is \emph{orthogonal to itself}.
This is just one aspect of the oddness of orthogonality under the Lorentz metric:
It is also the case that orthogonal vectors aren't generally at 90 degrees with respect to each other; in fact angles aren't obviously defined for general ($d\plus s$)-vectors in spacetime.
As for normalized, we will say that a ($d\plus s$)-vector is ``normalized'' or is a ``unit'' vector (and typeset it with a hat like $\Lhat{u}$ or $\Lhat{v}$) if the inner product with itself $\Lhat{u}^\top\metric\,\Lhat{u}$ is either $+1$ or $-1$.
\begin{align}
    \Lvec{u} ~ \mbox{is normalized iff} ~ |\Lvec{u}^\top\metric\,\Lvec{u}| = 1 ~.
\end{align}
Note that lightlike vectors cannot be normalized. We will still have linear dependence and independence exactly as in Euclidean space.
That is, $n$ ($d\plus s$)-vectors $\Lvec{a}_j$ are linearly independent if there is no non-trivial set of $n$ coefficients $\alpha_j\in\mathbb{R}$ such that $\sum_{j=1}^n \alpha_j\,\Lvec{a}_j = 0$.

How does orthonormalization work in relativity?
Start with $n\leq d+s$ linearly independent ($d\plus s$)-vectors $\Lvec{a}_1,\Lvec{a}_2,\ldots,\Lvec{a}_n$.
Provided that the first vector $\Lvec{a}_1$ is not lightlike, Gram--Schmidt works:
\begin{align}
    \Lvec{u}_1 &\leftarrow \Lvec{a}_1 \label{eq:rgs1}
    \\
    \mbox{then for each $j$ ($2\leq j\leq n$) in order:} \quad~ \Lvec{u}_j &\leftarrow \Lvec{a}_j - \sum_{k=1}^{j-1} \frac{\Lvec{a}_j^\top\metric\,\Lvec{u}_k}{\Lvec{u}_k^\top\metric\,\Lvec{u}_k}\,\Lvec{u}_k \label{eq:rgs2}
    \\
    \mbox{then for each $j$ ($1\leq j\leq n$):} \quad~ \Lhat{u}_j &\leftarrow \frac{1}{\sqrt{|\Lvec{u}_j^\top\metric\,\Lvec{u}_j|}}\,\Lvec{u}_j ~, \label{eq:rgs3}
\end{align}
where we had to insert an absolute value inside the square-root operation because negative inner products will appear.
We're done.

There is only one caveat:
The iteration step \eqref{eq:rgs2} involves dividing by the inner product $\Lvec{u}_k^\top\metric\,\Lvec{u}_k$, and the normalization step \eqref{eq:rgs3} involves dividing by the inner product $\Lvec{u}_j^\top\metric\,\Lvec{u}_j$, and these inner products can vanish if a lightlike vector appears.
Here are some comments and advice related to that eventuality:
\begin{itemize}
\item In fact it is very unlikely that the orthogonalization will produce a lightlike vector $\Lvec{u}_j$.
If the input vectors $\Lvec{a}_1,\Lvec{a}_2,\ldots,\Lvec{a}_n$ are generated randomly from typical kinds of distributions, for example, the probability of producing a lightlike vector in the orthogonalization vanishes.
\item It is critical that the first input vector is not lightlike: If the first vector $\Lvec{a}_1$ is lightlike, then a lightlike $\Lvec{u}_1$ is generated.
That said, as long as $\Lvec{a}_1$ is not lightlike, it is fine for subsequent vectors $\Lvec{a}_j$ ($j>1$) to be lightlike.
\item If all your input vectors $\Lvec{a}_1,\Lvec{a}_2,\ldots,\Lvec{a}_n$ are lightlike, then you ought to replace the first input vector $\Lvec{a}_1$ with a non-lightlike linear combination of the first two lightlike vectors.
Then with probability 1 the orthonormalization will succeed.
\item If the procedure produces a lightlike $\Lvec{u}_j$ at $j>1$, try reordering the vectors or replacing them with linearly independent linear combinations of one another.
Again, with probability 1 the orthonormalization will succeed.
\item If none of this works---that is, if even randomly generated linear combination of your input vectors produces a lightlike $\Lvec{u}_j$, then you are in a (very rare) boundary case, such that the subspace is tangent to the manifold of lightlike rays.
In this case there is no way to generate a orthonormal basis for the subspace.
The only recourse is to perturb the input vectors; that is, to orthogonalize a nearby set of inputs (that is, not precisely your original inputs).
Full characterization of these tangent cases is beyond the scope of this \documentname.
\end{itemize}
In what follows we will assume that you have an input set of $n$ ($d\plus s$)-vectors $\Lvec{a}_1,\Lvec{a}_2,\ldots,\Lvec{a}_n$ that leads, without any issues, to an output set of $n$ orthonormal basis ($d\plus s$)-vectors $\Lhat{u}_1,\Lhat{u}_2,\ldots,\Lhat{u}_n$.

The orthonormalization---when successful---returns complete coordinate bases:
If you start with $n=(d+s)$ linearly independent ($d\plus s$)-vectors, the outcome of the orthonormalization will be exactly $s$ timelike unit vectors and exactly $d$ spacelike vectors.
Importantly for what follows, \emph{the algorithm-generated set of normalized unit vectors $\Lhat{u}_1,\Lhat{u}_2,\ldots,\Lhat{u}_{d+s}$ will form a coordinate basis in spacetime}, with $s$ orthogonal timelike (time) axis unit vectors and $d$ orthogonal spacelike (spatial) axis unit vectors.
If you start with $n<(d+s)$ linearly independent ($d\plus s$)-vectors, the outcome of the orthonormalization will be $q\leq s$ timelike unit vectors and $p\leq d$ spacelike unit vectors, with $n=(p+q)$
The $n$-dimensional subspace spanned by these orthonormal vectors will be a $p\plus q$ spacetime, governed by the Lorentz group O($q,p$).
And, in some M-theory or brane contexts, it is possible that we live on a $3\plus 1$ subspace of some larger spacetime with $d+s\geq 10$ \cite{branes, strings}.

By the way, there are other kinds of bases in special and general relativity, in which lightlike vectors are preferentially used as basis vectors.
In these cases the lightlike basis vectors can't be normalized (because lightlike vectors cannot be normalized in a coordinate-independent way).
These bases are out of scope here, because they aren't useful for what follows.

Now just like in Euclidean space you can use the orthonormalization to make a subspace projection operator in spacetime.
If you have $n\leq d+s$ linearly independent ($d\plus s$)-vectors that span a subspace $\mathscr{T}$, then you can orthonormalize them and construct the subspace projection operator $\proj_\mathscr{T}$
\begin{align}\label{eq:rproj}
    \proj_\mathscr{T} &= \sum_{j=1}^n \frac{\Lhat{u}_j\,\Lhat{u}_j^\top\metric}{\Lhat{u}_j^\top\metric\,\Lhat{u}_j} = \sum_{j=1}^n \frac{\Lvec{u}_j\,\Lvec{u}_j^\top\metric}{\Lvec{u}_j^\top\metric\,\Lvec{u}_j} ~,
\end{align}
where the $\Lhat{u}_j$ are the orthogonal unit vectors, and the $\Lvec{u}_j$ are the un-normalized orthogonal vectors; this differs from the result in \eqref{eq:oproj} in that we have to divide by an inner product $\Lhat{u}_j^\top\metric\,\Lhat{u}_j$ to account for the sign of the inner product, and we have a right multiply of the metric $\metric$.
But notice that \eqref{eq:rproj} reduces to \eqref{eq:oproj} when the metric is the identity (and thus all inner products are positive).
This projection operator $\proj_\mathscr{T}$ has the property that, for any ($d\plus s$)-vector $\Lvec{b}$, the ($d\plus s$)-vector $\proj_\mathscr{T}\,\Lvec{b}$ will lie in the subspace $\mathscr{T}$ spanned by the $n$ original ($d\plus s$)-vectors $\Lvec{a}_j$ that were orthonormalized.
Again, the projection operator $\proj_{\mathscr{T}^\perp}$ into the complementary subspace $\mathscr{T}^\perp$ is then just
\begin{align}\label{eq:lprojcomp}
    \proj_{\mathscr{T}^\perp} &= I_{d+s} - \proj_\mathscr{T} ~,
\end{align}
where $I_{d+s}$ is the $(d+s)\times(d+s)$ identity.

If you have a full set of $n=d+s$ linearly independent ($d\plus s$)-vectors $\Lvec{a}_j$, they will span the whole ($d\plus s$)-dimensional space, and the projection operator $\proj_\mathscr{T}$ will become the identity $I_{d+s}$.
That is, if you have an orthonormal basis of $d+s$ unit vectors $\Lhat{u}_j$, then
\begin{align}
    I_{d+s} &= \sum_{j=1}^{d+s} \frac{\Lhat{u}_j\,\Lhat{u}_j^\top\metric}{\Lhat{u}_j^\top\metric\,\Lhat{u}_j} = \sum_{j=1}^{d+s} \frac{\Lvec{u}_j\,\Lvec{u}_j^\top\metric}{\Lvec{u}_j^\top\metric\,\Lvec{u}_j} \label{eq:Lidentity} ~,
\end{align}
where we have written it in terms of both the normalized and un-normalized orthogonal vectors; note that $\Lhat{u}_j^\top\metric\,\Lhat{u}_j=\pm 1$.

Because the metric is its own inverse, if we right-multiply by the metric, we make a simple expression for the metric $\metric$ in terms of the basis vectors:
\begin{align}
    \metric &= \sum_{j=1}^{d+s} \frac{\Lhat{u}_j\,\Lhat{u}_j^\top}{\Lhat{u}_j^\top\metric\,\Lhat{u}_j} = \sum_{j=1}^{d+s} \frac{\Lvec{u}_j\,\Lvec{u}_j^\top}{\Lvec{u}_j^\top\metric\,\Lvec{u}_j} ~.
\end{align}
This expression is beautifully independent of the signature of the metric; it works for either signature.

If your background is quantum mechanics, then you probably use bra--ket and ket--bra (Dirac) notation \cite{dirac}.
For you, an inner product of unit vectors (basis vectors) ought to be written as a bra--ket $\braket{\Lhat{u}}{\Lhat{v}}$, and an outer product of unit vectors ought to be written as a ket--bra $\ketbra{\Lhat{u}}{\Lhat{v}}$.
In this quantum-mechanics (bra--ket) notation, a covariant vector (plus some decorations) becomes a bra $\bra{\Lhat{v}}$, and a contravariant vector becomes a ket $\ket{\Lhat{v}}$
\begin{align}
    \ket{\Lhat{u}_j} &\equiv \Lhat{u}_j \label{eq:ket}\\
    \bra{\Lhat{u}_j} &\equiv \frac{1}{\Lhat{u}_j^\top\metric\,\Lhat{u}_j}\,\Lhat{u}_j^\top\metric ~,\label{eq:bra} ~,
\end{align}
where we have taken some liberties in defining the bra $\bra{\Lhat{u}_j}$, and we remind you that $\Lhat{u}_j^\top\metric\,\Lhat{u}_j=\pm 1$.
With these definitions, the expression for the identity \eqref{eq:Lidentity} becomes a standard formula in quantum mechanics:
\begin{align}
    I_{d+s} &= \sum_{j=1}^{d+s} \ketbra{\Lhat{u}_j}{\Lhat{u}_j} \label{eq:LidentityQM} ~.
\end{align}
We'll use this simplifying bra--ket notation below.
Note that even though the inner product $\Lhat{u}^\top\metric\,\Lhat{u}$ can be either $+1$ or $-1$, with these definitions, the bra--ket $\braket{\Lhat{u}}{\Lhat{u}}$ is always $+1$, whether $\Lhat{u}$ is timelike or spacelike.

\section{Vector-guided Lorentz transformations}\label{sec:lt}

All this work with orthonormal ($d\plus s$)-vectors in special relativity is in the service of making a coordinate-free expression for the Lorentz transformation.
Consider two observers moving through spacetime.
One (unprime) is moving with ($d\plus s$)-vector velocity $\Lhat{u}$ and the other (prime) is moving with ($d\plus s$)-vector velocity $\Lhat{v}$.
It is a property of any ($d\plus s$)-vector velocity that it is timelike, and we have typeset them as unit vectors because it is also true that any ($d\plus s$)-vector velocity has norm 1 (it is a unit vector)
Each of these two observers has a rest frame, and if $\Lhat{u}-\Lhat{v}\neq 0$, those two rest frames are different.
What are the Lorentz transformations between the two frames?
That is, how do I construct transformations $Q\in\mbox{O($s,d$)}$ that boost $\Lhat{u}$ to make it parallel to $\Lhat{v}$, and vice versa?

There are two answers.
The first answer is that one can augment the ($d\plus s$)-vector velocity $\Lhat{u}$ with $d$ additional ($d\plus s$)-vectors $\Lvec{a}_2,\Lvec{a}_3,\ldots,\Lvec{a}_{d+s}$, and we augment the ($d\plus s$)-vector velocity $\Lhat{v}$ with $d$ additional ($d\plus s$)-vectors $\Lvec{b}_2,\Lvec{b}_3,\ldots,\Lvec{b}_{d+s}$.
If you want the Lorentz transformation to have no rotation or reflections, you can set $\Lvec{a}_k=\Lvec{b}_k$ for all $k\geq 2$.
Then you orthonormalize the unprimed vectors, with the input order $\Lvec{u},\Lvec{a}_2,\ldots,\Lvec{a}_{d+s}$, to get orthonormal basis vectors $\Lhat{u}_1,\Lhat{u}_2,\ldots,\Lhat{u}_{d+s}$, and you orthonormalize the primed vectors, with the input order $\Lvec{v},\Lvec{b}_2,\ldots,\Lvec{b}_{d+s}$, to get orthonormal basis vectors $\Lhat{v}_1,\Lhat{v}_2,\ldots,\Lhat{v}_{d+s}$.
Armed with these orthonormal basis vectors, the Lorentz transformation $Q$ that boosts from the unprimed frame to the primed frame is simply
\begin{align}
  Q = \sum_{j=1}^{d+s} \ketbra{\Lhat{v}_j}{\Lhat{u}_j} \quad~ \mbox{iff} ~ \Lhat{u}_j^\top\metric\,\Lhat{u}_j = \Lhat{v}_j^\top\metric\,\Lhat{v}_j = \pm 1 ~ \mbox{for all $j$} \label{eq:LTQM} ~,
\end{align}
where we have defined the kets and bras as in \eqref{eq:ket} and \eqref{eq:bra}.
This expression is the relativistic (Lorentz) generalization of the rotation--reflection operator in Euclidean space given in \eqref{eq:rotationoperator}.
If we expand the kets and bras back to the linear-algebra forms, this expression becomes
\begin{align}
  Q &= \sum_{j=1}^{d+s} \frac{\Lhat{v}_j\,\Lhat{u}_j^\top\metric}{\Lhat{u}_j^\top\metric\,\Lhat{u}_j} \quad~ \mbox{iff} ~ \Lhat{u}_j^\top\metric\,\Lhat{u}_j = \Lhat{v}_j^\top\metric\,\Lhat{v}_j = \pm 1 ~ \mbox{for all $j$} ~.
\end{align}

A few comments about expression $\eqref{eq:LTQM}$ for the Lorentz transformation $Q$ could be the following:
The orthonormalization (almost) always returns $s$ timelike and $d$ spacelike vectors;
provided that these are ordered such that they match, that is, provided that $\Lhat{u}_k^\top\metric\,\Lhat{u}_k=\Lhat{v}_k^\top\metric\,\Lhat{v}_k$ for all $k$, the construction of $Q$ given by \eqref{eq:LTQM} will be a valid Lorentz transformation.
If (as is sensible) the inputs are ordered such that the first input vector ($\Lvec{a}_1$ in the orthonormalization procedure) is timelike, the orthonormalization will make the first output unit vector $\Lhat{u}_1$ be timelike.
If the first input vector is a ($d\plus s$)-vector velocity $\Lhat{u}$ (that is, timelike and unit norm), then the the first output vector $\Lhat{u}_1$ will be identical to the input vector $\Lhat{u}$.
The expression \eqref{eq:LTQM} is coordinate free and independent of the signature choice.
Finally, direct calculation will show that the expression \eqref{eq:LTQM} for $Q$ satisfies the definition \eqref{eq:lore2} of a Lorentz transformation.
% \HOGG{Many of these comments maybe don't deserve to be here, exactly? Reconsider these.}

\begin{figure}[t]
\begin{mdframed}
\includegraphics[width=\figurewidth]{L_v.png}%
\includegraphics[width=\figurewidth]{L_vp.png}%
\includegraphics[width=\figurewidth]{L_Q.png}
\caption{A demonstration of orthonormalization and rotation in Lorentz $1\plus 1$-dimensional space O($1,1$).
The time coordinate (the first coordinate) is plotted on the vertical axis and the space coordinate (the second coordinate) is plotted on the horizontal axis.
\textsl{Left:} Two ($1\plus1$)-vectors $\Lvec{a}_1, \Lvec{a}_2$ and the corresponding orthonormal ($1\plus1$)-vectors $\Lhat{u}_1, \Lhat{u}_2$ obtained by the orthonormalization procedure.
Note that orthonormal vectors in $1\plus1$ neither look orthogonal nor normalized to the eye.
The loci of (the tips of) normalized ($1\plus1$)-vectors are plotted as smooth curves to show the hyperbolic structure of the space.
\textsl{Middle:} A different two ($1\plus1$)-vectors $\Lvec{b}_1, \Lvec{b}_2$ and the corresponding orthonormal ($1\plus1$)-vectors $\Lhat{v}_1, \Lhat{v}_2$.
\textsl{Right:} The action of the transformation operator (Lorentz transformation) $Q$ generated from the orthonormal pairs $\Lhat{u}_1, \Lhat{u}_2$ and $\Lhat{v}_1, \Lhat{v}_2$.
The black points transform to the red points under the action of the operator $Q$.
The grey points in between are presented to guide the eye; 
note that they trace out not segments of circles (compare to \figref{fig:Euclid}) but instead segments of hyperbolae.\label{fig:Lorentz}}
\end{mdframed}
\end{figure}
The expression \eqref{eq:LTQM} is a coordinate-free expression for the Lorentz transformation, in terms of coordinate basis ($d\plus s$)-vectors.
This is the main contribution of this \documentname.
\figref{fig:Lorentz} illustrates the orthonormalization and the action of the Lorentz transformation so constructed in $(1\plus1)$.

In detail, any Lorentz transformation can be thought of as being a composition of a boosts, time-reversals, a time rotation (when $s>1$), a spatial rotation, and spatial reflections.
Often when we discuss Lorentz transformations, we want transformations that are boost only.
The procedure above delivers a boost-only transformation when the two lists of ($d\plus s$)-vectors to be orthonormalized are identical except for the first elements, both of which are timelike.
Spatial rotations and reflections can be introduced by modifying the two lists of ($d\plus s$)-vectors that follow the first (timelike) elements.
The full discussion of all these options is beyond our scope here.

The oddest kind of Lorentz transformation is one that reverses the time direction.
We don't recommend making such transformations, but they are permitted here.
These can be constructed by multiplying one of the input ($d\plus s$)-vector velocities (either $\Lhat{u}$ or $\Lhat{v}$) by $-1$ before starting the orthonormalization.

The second answer to our question---how to construct the Lorentz transformation $Q$ starting with two input ($d\plus s$)-vector velocities $\Lhat{u}$ and $\Lhat{v}$---is to write down the ``minimal'' Lorentz transformation $Q$ that transforms $\Lhat{u}$ to $\Lhat{v}$.
By ``minimal'' here we mean, in some sense, ``closest to the identity.''
It is minimal in the same sense that the Euclidean rotation operator given in \eqref{eq:vecs2rot} is the minimum-angle rotation that brings the one direction to the other.
The Lorentz generalization of that Euclidean expression is
\begin{align}
    Q &= \ketbra{\Lhat{v}}{\Lhat{u}} - \ketbra{\Lhat{u}}{\Lhat{v}} + \braket{\Lhat{u}}{\Lhat{v}}\,\proj_{uv} + \proj_{uv^\perp} \quad~ \mbox{iff} ~ \Lhat{u}^\top\metric\,\Lhat{u} = \Lhat{v}^\top\metric\,\Lhat{v} = \pm 1 \label{eq:vecs2LT} \\
    \proj_{uv} &= \frac{\left(\ketbra{\Lhat{u}}{\Lhat{u}} + \ketbra{\Lhat{v}}{\Lhat{v}}\right) - \braket{\Lhat{u}}{\Lhat{v}}\,\left(\ketbra{\Lhat{u}}{\Lhat{v}} + \ketbra{\Lhat{v}}{\Lhat{u}}\right)}{1 - \braket{\Lhat{u}}{\Lhat{v}}^2} ~,
\end{align}
where $\proj_{uv}$ is the projection operator into the subspace spanned by $\Lhat{u}$ and $\Lhat{v}$,
and $\proj_{uv^\perp} = I_{d+s} - \proj_{uv}$ is the complementary projection operator.
This Lorentz transformation \eqref{eq:vecs2LT} boosts from $\Lhat{u}$ to $\Lhat{v}$, but it does not modify any ($d\plus s$)-vector that is orthogonal to the subspace spanned by $\Lhat{u}$ and $\Lhat{v}$.

A few comments about the expression \eqref{eq:vecs2LT} could be the following:
The initial problem statement started with two timelike unit vectors, $\Lhat{u}$ and $\Lhat{v}$.
In fact, this expression works for timelike or spacelike vectors.
The only condition is that they be normalized, and that they be either both timelike or both spacelike.
Timelike and spacelike cannot be mixed.
When $s=1$ and the two vectors are timelike, the expression \eqref{eq:vecs2LT} produces a pure boost (and possibly also a time 
and space reversal);
when $s>1$ and the two vectors are timelike, the expression produces both a time-domain rotation and a boost in general;
when the two vectors are spacelike, the expression produces both a spatial rotation and a boost in general.
We derived the expression by explicitly orthonormalizing and constructing \eqref{eq:LTQM} for the case in which the transformation acts only in the subspace spanned by $\Lhat{u}$ and $\Lhat{v}$.
Expression \eqref{eq:vecs2LT} is less general than expression \eqref{eq:LTQM}, because it cannot produce spatial reflections.
However, like \eqref{eq:LTQM}, the expression \eqref{eq:vecs2LT} is coordinate free and independent of the signature choice.
Direct calculation shows that the expression \eqref{eq:vecs2LT} for $Q$ satisfies the definition \eqref{eq:lore2} of a Lorentz transformation.

Finally, connecting this to standard teaching practice, we make the remark that if $\Lhat{u}$ is the ($d\plus s$)-vector velocity of the ``lab frame'' and $\Lhat{v}$ is the ($d\plus s$)-vector velocity of the ``rocket frame'' then the expression \eqref{eq:vecs2LT} delivers the pure boost Lorentz transformation that changes between these frames.
These are the standard Lorentz transformations that are sought and used in the introductory textbooks on the subject.
The use of the transformation can be seen as something that changes ($d\plus s$)-vectors (``alibi'' in the Weyl sense \cite{weyl}),
or it can be seen as something that changes the coordinate system in which those vectors are represented (``alias'' in the Weyl sense).
In the alibi sense, $Q$ boosts (as a rocket might) events and ($d\plus s$)-vectors from the lab frame to the rocket frame.
In the alias sense, $Q$ shows how events and ($d\plus s$)-vectors appearing in the rocket frame will appear when described in the lab frame.
Most (but not all) practical uses of Lorentz transformations are alias;
that is, the Lorentz transformation is usually used to understand how the same events look in different coordinate systems.
The captions of \figref{fig:Euclid} and \figref{fig:Lorentz} use suggestively alibi language; for this we apologize.

\section{Discussion}\label{sec:discussion}

We have recommended a procedure to make orthonormal basis vectors, and shown how to use these to construct Lorentz transformations.
The procedure is to take a set of ($d\plus s$)-vectors (close to or exactly basis vectors is best) in each frame, orthonormalize according to \eqref{eq:rgs1} through \eqref{eq:rgs3}, and then use the output to construct the Lorentz transformation according to \eqref{eq:LTQM}, which in turn depends on ket and bra definitions in \eqref{eq:ket} and \eqref{eq:bra}.
If you want your Lorentz transformation to specifically boost from one frame to another frame, your input vector lists should start with the two ($d\plus s$)-vector velocities of the two frames; that is, the velocities should be the first vectors in the lists provided to the orthonormalization algorithm.

These new constructions for Lorentz transformations are explicitly coordinate free; they depend only on the input vectors, and not on the coordinate system in which they are represented.
Importantly, our formalism can produce any Lorentz transformation, including arbitrary compositions of boosts, time reversals, spatial rotations, and spatial reflections.
Much of our discussion is very mathematical and theoretical.
However, the new parameterization \eqref{eq:LTQM} of the Lorentz transformation is completely general, works in all $d+s$ spacetimes, and is far simpler to state than the most general coordinate-based (that is, not coordinate-free) expressions for the Lorentz transformation (see, eg, \cite{haber}).

We have a very inclusive definition of the Lorentz transformation; for us any operator $Q$ is a Lorentz transformation if $Q^\top\metric\,Q=\metric$, where $\metric$ is the spacetime metric.
Thus, for us, Lorentz transformations include all arbitrary compositions of boost, time reversal, rotation, and spatial reflection.
Our parameterization covers all of these, naturally.
That is, our parameterization generates all possible elements of the group O($s,d$).
Others might restrict to a smaller set; in which case there are additional constraints beyond our definitions \eqref{eq:lore1} and \eqref{eq:lore2}; this would, in turn, restrict the orthonormal vector inputs to our expression \eqref{eq:LTQM} for the Lorentz transformation.
For example, some would require $\det Q = +1$, thinking that this will remove pathologies.
Unfortunately it doesn't, because you can reverse time and still have $\det Q = +1$ provided that you also flip space (or even worse things if you have multiple times or $s>1$).

The tangent-space or boundary cases in which subspaces of $d\plus s$ cannot be orthogonalized without generating nulls is a very interesting subject, and shows non-trivial phenomenology in $d\plus s$ when $d$ and $s$ get large.
We have an intuition that these cases can be removed with infinitesimal perturbations or limits, but we don't have an explicit solution.
One interesting fact is that if you obey the orthonormalization procedure described in \eqref{eq:rgs1} through \eqref{eq:rgs3} on a set of $k$ vectors spanning one of these pathological subspaces, the null basis vector will, with probability 1, be produced last (at position $k$) by the algorithm.
In the even more pathological case of multiply-tangent spaces, the multiple null basis vectors get produced at the end of the list.
There is obviously a lot of interesting geometry to explore here.
That said, in most concepts of large Lorentz spaces (as arise in string theory, say; \cite{strings}), it is usually assumed that the space is $d+1$, not $d+s$.
Fundamentally this is because those theories are careful to avoid closed timelike curves at compactification.
So although there are pathological subspaces in these theories, the case of large values of $s$ doesn't arise much (or at all) in the physics literature.
It's also pretty hard to imagine living in a universe with multiple times!

As the sum $d+s$ gets large, the orthonormalization can get numerically unstable, especially in adversarial situations.
Most relativity work is at $d+s\leq 4$ (or conceivably 10, 11, or 26 if you are a string theorist) so numerical stability shouldn't be much of a problem.
However, an easy improvement to stability might be to move from Gram--Schmidt to Modified Gram--Schmidt \cite{modifiedgramschmidt}.
That move can be made here too, without significant work.

This contribution is purely technical, in the sense that we aren't advocating any particular \emph{use} of the orthonormalization or the Lorentz transformations; we are assuming that the reader needs these.
The methods and expressions developed here are very easy to implement in clear and pragmatic code.
That is, even if you are writing code in a specific coordinate system, these expressions are easy to implement and use; much easier than specifying all coordinate-dependent angles, reflections, and boosts in $d\plus s$.
A trivial use of these expressions in code is demonstrated in the sample code associated with this \documentname.
This code numerically tests the expressions developed here, makes the figures, and is available under an open-source license at \url{https://github.com/davidwhogg/RelativisticOrthogonalization}.

\paragraph{Acknowledgements:}
It is a pleasure to thank
  Roger Blandford (Stanford),
  Ben Blum-Smith (JHU),
  Alex Jiang (CUNY),
  Clark Miyamoto (NYU), and
  Monica Pate (NYU)
for valuable discussions.
% SOLE GRANT NUMBERS?
The Flatiron Institute is a division of the Simons Foundation.

\raggedright
\bibliographystyle{IEEEtran}
\bibliography{sr}
\end{document}
